{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing binary decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this notebook is to implement your own binary decision tree classifier. You will:\n",
    "    \n",
    "* Use SFrames to do some feature engineering.\n",
    "* Transform categorical variables into binary variables.\n",
    "* Write a function to compute the number of misclassified examples in an intermediate node.\n",
    "* Write a function to find the best feature to split on.\n",
    "* Build a binary decision tree from scratch.\n",
    "* Make predictions using the decision tree.\n",
    "* Evaluate the accuracy of the decision tree.\n",
    "* Visualize the decision at the root node.\n",
    "\n",
    "**Important Note**: In this assignment, we will focus on building decision trees where the data contain **only binary (0 or 1) features**. This allows us to avoid dealing with:\n",
    "* Multiple intermediate nodes in a split\n",
    "* The thresholding issues of real-valued features.\n",
    "\n",
    "This assignment **may be challenging**, so brace yourself :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fire up Turi Create"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you have the latest version of Turi Create."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import turicreate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the lending club dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using the same [LendingClub](https://www.lendingclub.com/) dataset as in the previous assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans = turicreate.SFrame('lending-club-data.sframe/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like the previous assignment, we reassign the labels to have +1 for a safe loan, and -1 for a risky (bad) loan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans['safe_loans'] = loans['bad_loans'].apply(lambda x : +1 if x==0 else -1)\n",
    "loans = loans.remove_column('bad_loans')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike the previous assignment where we used several features, in this assignment, we will just be using 4 categorical\n",
    "features: \n",
    "\n",
    "1. grade of the loan \n",
    "2. the length of the loan term\n",
    "3. the home ownership status: own, mortgage, rent\n",
    "4. number of years of employment.\n",
    "\n",
    "Since we are building a binary decision tree, we will have to convert these categorical features to a binary representation in a subsequent section using 1-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['grade',              # grade of the loan\n",
    "            'term',               # the term of the loan\n",
    "            'home_ownership',     # home_ownership status: own, mortgage or rent\n",
    "            'emp_length',         # number of years of employment\n",
    "           ]\n",
    "target = 'safe_loans'\n",
    "loans = loans[features + [target]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore what the dataset looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\"><table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">grade</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">term</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">home_ownership</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">emp_length</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">safe_loans</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">B</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\"> 36 months</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">RENT</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">10+ years</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">C</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\"> 60 months</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">RENT</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">&lt; 1 year</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">C</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\"> 36 months</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">RENT</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">10+ years</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">C</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\"> 36 months</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">RENT</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">10+ years</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">A</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\"> 36 months</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">RENT</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3 years</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">E</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\"> 36 months</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">RENT</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">9 years</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">F</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\"> 60 months</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">OWN</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">4 years</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">B</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\"> 60 months</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">RENT</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">&lt; 1 year</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">C</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\"> 60 months</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">OWN</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5 years</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">B</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\"> 36 months</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">OWN</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">10+ years</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "    </tr>\n",
       "</table>\n",
       "[122607 rows x 5 columns]<br/>Note: Only the head of the SFrame is printed.<br/>You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns.\n",
       "</div>"
      ],
      "text/plain": [
       "Columns:\n",
       "\tgrade\tstr\n",
       "\tterm\tstr\n",
       "\thome_ownership\tstr\n",
       "\temp_length\tstr\n",
       "\tsafe_loans\tint\n",
       "\n",
       "Rows: 122607\n",
       "\n",
       "Data:\n",
       "+-------+------------+----------------+------------+------------+\n",
       "| grade |    term    | home_ownership | emp_length | safe_loans |\n",
       "+-------+------------+----------------+------------+------------+\n",
       "|   B   |  36 months |      RENT      | 10+ years  |     1      |\n",
       "|   C   |  60 months |      RENT      |  < 1 year  |     -1     |\n",
       "|   C   |  36 months |      RENT      | 10+ years  |     1      |\n",
       "|   C   |  36 months |      RENT      | 10+ years  |     1      |\n",
       "|   A   |  36 months |      RENT      |  3 years   |     1      |\n",
       "|   E   |  36 months |      RENT      |  9 years   |     1      |\n",
       "|   F   |  60 months |      OWN       |  4 years   |     -1     |\n",
       "|   B   |  60 months |      RENT      |  < 1 year  |     -1     |\n",
       "|   C   |  60 months |      OWN       |  5 years   |     1      |\n",
       "|   B   |  36 months |      OWN       | 10+ years  |     1      |\n",
       "+-------+------------+----------------+------------+------------+\n",
       "[122607 rows x 5 columns]\n",
       "Note: Only the head of the SFrame is printed.\n",
       "You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsample dataset to make sure classes are balanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as we did in the previous assignment, we will undersample the larger class (safe loans) in order to balance out our dataset. This means we are throwing away many data points. We use `seed=1` so everyone gets the same results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of safe loans                 : 0.5022361744216048\n",
      "Percentage of risky loans                : 0.4977638255783951\n",
      "Total number of loans in our new dataset : 46508\n"
     ]
    }
   ],
   "source": [
    "safe_loans_raw = loans[loans[target] == 1]\n",
    "risky_loans_raw = loans[loans[target] == -1]\n",
    "\n",
    "# Since there are less risky loans than safe loans, find the ratio of the sizes\n",
    "# and use that percentage to undersample the safe loans.\n",
    "percentage = len(risky_loans_raw)/float(len(safe_loans_raw))\n",
    "safe_loans = safe_loans_raw.sample(percentage, seed = 1)\n",
    "risky_loans = risky_loans_raw\n",
    "loans_data = risky_loans.append(safe_loans)\n",
    "\n",
    "print(\"Percentage of safe loans                 :\", len(safe_loans) / float(len(loans_data)))\n",
    "print(\"Percentage of risky loans                :\", len(risky_loans) / float(len(loans_data)))\n",
    "print(\"Total number of loans in our new dataset :\", len(loans_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** There are many approaches for dealing with imbalanced data, including some where we modify the learning algorithm. These approaches are beyond the scope of this course, but some of them are reviewed in \"[Learning from Imbalanced Data](http://www.ele.uri.edu/faculty/he/PDFfiles/ImbalancedLearning.pdf)\" by Haibo He and Edwardo A. Garcia, *IEEE Transactions on Knowledge and Data Engineering* **21**(9) (June 26, 2009), p. 1263–1284. For this assignment, we use the simplest possible approach, where we subsample the overly represented class to get a more balanced dataset. In general, and especially when the data is highly imbalanced, we recommend using more advanced methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform categorical data into binary features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, we will implement **binary decision trees** (decision trees for binary features, a specific case of categorical variables taking on two values, e.g., true/false). Since all of our features are currently categorical features, we want to turn them into binary features. \n",
    "\n",
    "For instance, the **home_ownership** feature represents the home ownership status of the loanee, which is either `own`, `mortgage` or `rent`. For example, if a data point has the feature \n",
    "```\n",
    "   {'home_ownership': 'RENT'}\n",
    "```\n",
    "we want to turn this into three features: \n",
    "```\n",
    " { \n",
    "   'home_ownership = OWN'      : 0, \n",
    "   'home_ownership = MORTGAGE' : 0, \n",
    "   'home_ownership = RENT'     : 1\n",
    " }\n",
    "```\n",
    "\n",
    "Since this code requires a few Python and Turi Create tricks, feel free to use this block of code as is. Refer to the API documentation for a deeper understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_data = risky_loans.append(safe_loans)\n",
    "for feature in features:\n",
    "    loans_data_one_hot_encoded = loans_data[feature].apply(lambda x: {x: 1})    \n",
    "    loans_data_unpacked = loans_data_one_hot_encoded.unpack(column_name_prefix=feature)\n",
    "    \n",
    "    # Change None's to 0's\n",
    "    for column in loans_data_unpacked.column_names():\n",
    "        loans_data_unpacked[column] = loans_data_unpacked[column].fillna(0)\n",
    "\n",
    "    loans_data = loans_data.remove_column(feature)\n",
    "    loans_data = loans_data.add_columns(loans_data_unpacked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what the feature columns look like now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['grade.A',\n",
       " 'grade.B',\n",
       " 'grade.C',\n",
       " 'grade.D',\n",
       " 'grade.E',\n",
       " 'grade.F',\n",
       " 'grade.G',\n",
       " 'term. 36 months',\n",
       " 'term. 60 months',\n",
       " 'home_ownership.MORTGAGE',\n",
       " 'home_ownership.OTHER',\n",
       " 'home_ownership.OWN',\n",
       " 'home_ownership.RENT',\n",
       " 'emp_length.1 year',\n",
       " 'emp_length.10+ years',\n",
       " 'emp_length.2 years',\n",
       " 'emp_length.3 years',\n",
       " 'emp_length.4 years',\n",
       " 'emp_length.5 years',\n",
       " 'emp_length.6 years',\n",
       " 'emp_length.7 years',\n",
       " 'emp_length.8 years',\n",
       " 'emp_length.9 years',\n",
       " 'emp_length.< 1 year',\n",
       " 'emp_length.n/a']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = loans_data.column_names()\n",
    "features.remove('safe_loans')  # Remove the response variable\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features (after binarizing categorical variables) = 25\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of features (after binarizing categorical variables) = %s\" % len(features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore what one of these columns looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype: int\n",
       "Rows: 46508\n",
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, ... ]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loans_data['grade.A']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This column is set to 1 if the loan grade is A and 0 otherwise.\n",
    "\n",
    "**Checkpoint:** Make sure the following answers match up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of grade.A loans : 6422\n",
      "Expexted answer               : 6422\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of grade.A loans : %s\" % loans_data['grade.A'].sum())\n",
    "print(\"Expexted answer               : 6422\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test split\n",
    "\n",
    "We split the data into a train test split with 80% of the data in the training set and 20% of the data in the test set. We use `seed=1` so that everyone gets the same result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = loans_data.random_split(.8, seed=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will implement binary decision trees from scratch. There are several steps involved in building a decision tree. For that reason, we have split the entire assignment into several sections.\n",
    "\n",
    "## Function to count number of mistakes while predicting majority class\n",
    "\n",
    "Recall from the lecture that prediction at an intermediate node works by predicting the **majority class** for all data points that belong to this node.\n",
    "\n",
    "Now, we will write a function that calculates the number of **missclassified examples** when predicting the **majority class**. This will be used to help determine which feature is the best to split on at a given node of the tree.\n",
    "\n",
    "**Note**: Keep in mind that in order to compute the number of mistakes for a majority classifier, we only need the label (y values) of the data points in the node. \n",
    "\n",
    "** Steps to follow **:\n",
    "* **Step 1:** Calculate the number of safe loans and risky loans.\n",
    "* **Step 2:** Since we are assuming majority class prediction, all the data points that are **not** in the majority class are considered **mistakes**.\n",
    "* **Step 3:** Return the number of **mistakes**.\n",
    "\n",
    "\n",
    "Now, let us write the function `intermediate_node_num_mistakes` which computes the number of misclassified examples of an intermediate node given the set of labels (y values) of the data points contained in the node. Fill in the places where you find `## YOUR CODE HERE`. There are **three** places in this function for you to fill in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intermediate_node_num_mistakes(labels_in_node):\n",
    "    # Corner case: If labels_in_node is empty, return 0\n",
    "    if len(labels_in_node) == 0:\n",
    "        return 0\n",
    "    \n",
    "    # Count the number of 1's (safe loans)\n",
    "    ## YOUR CODE HERE\n",
    "    countPos = len(labels_in_node.filter(lambda x: x == 1))\n",
    "    \n",
    "    # Count the number of -1's (risky loans)\n",
    "    ## YOUR CODE HERE\n",
    "    countNeg = len(labels_in_node.filter(lambda x: x == -1))\n",
    "    \n",
    "    if countPos >= countNeg:\n",
    "        result = countNeg\n",
    "    else:    \n",
    "        result = countPos\n",
    "\n",
    "    #print(\"labels_in_node: \", labels_in_node)\n",
    "    #print(\"countPos: \", countPos)\n",
    "    #print(\"countNeg: \", countNeg)\n",
    "    #print(\"result: \", result)\n",
    "    \n",
    "    return result   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because there are several steps in this assignment, we have introduced some stopping points where you can check your code and make sure it is correct before proceeding. To test your `intermediate_node_num_mistakes` function, run the following code until you get a **Test passed!**, then you should proceed. Otherwise, you should spend some time figuring out where things went wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed!\n",
      "Test passed!\n",
      "Test passed!\n"
     ]
    }
   ],
   "source": [
    "# Test case 1\n",
    "example_labels = turicreate.SArray([-1, -1, 1, 1, 1])\n",
    "if intermediate_node_num_mistakes(example_labels) == 2:\n",
    "    print('Test passed!')\n",
    "else:\n",
    "    print('Test 1 failed... try again!')\n",
    "\n",
    "# Test case 2\n",
    "example_labels = turicreate.SArray([-1, -1, 1, 1, 1, 1, 1])\n",
    "if intermediate_node_num_mistakes(example_labels) == 2:\n",
    "    print('Test passed!')\n",
    "else:\n",
    "    print('Test 2 failed... try again!')\n",
    "\n",
    "# Test case 3\n",
    "example_labels = turicreate.SArray([-1, -1, -1, -1, -1, 1, 1])\n",
    "if intermediate_node_num_mistakes(example_labels) == 2:\n",
    "    print('Test passed!')\n",
    "else:\n",
    "    print('Test 3 failed... try again!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to pick best feature to split on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function **best_splitting_feature** takes 3 arguments: \n",
    "1. The data (SFrame of data which includes all of the feature columns and label column)\n",
    "2. The features to consider for splits (a list of strings of column names to consider for splits)\n",
    "3. The name of the target/label column (string)\n",
    "\n",
    "The function will loop through the list of possible features, and consider splitting on each of them. It will calculate the classification error of each split and return the feature that had the smallest classification error when split on.\n",
    "\n",
    "Recall that the **classification error** is defined as follows:\n",
    "$$\n",
    "\\mbox{classification error} = \\frac{\\mbox{# mistakes}}{\\mbox{# total examples}}\n",
    "$$\n",
    "\n",
    "Follow these steps: \n",
    "* **Step 1:** Loop over each feature in the feature list\n",
    "* **Step 2:** Within the loop, split the data into two groups: one group where all of the data has feature value 0 or False (we will call this the **left** split), and one group where all of the data has feature value 1 or True (we will call this the **right** split). Make sure the **left** split corresponds with 0 and the **right** split corresponds with 1 to ensure your implementation fits with our implementation of the tree building process.\n",
    "* **Step 3:** Calculate the number of misclassified examples in both groups of data and use the above formula to compute the **classification error**.\n",
    "* **Step 4:** If the computed error is smaller than the best error found so far, store this **feature and its error**.\n",
    "\n",
    "This may seem like a lot, but we have provided pseudocode in the comments in order to help you implement the function correctly.\n",
    "\n",
    "**Note:** Remember that since we are only dealing with binary features, we do not have to consider thresholds for real-valued features. This makes the implementation of this function much easier.\n",
    "\n",
    "Fill in the places where you find `## YOUR CODE HERE`. There are **five** places in this function for you to fill in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_splitting_feature(data, features, target):\n",
    "    \n",
    "    best_feature = None # Keep track of the best feature \n",
    "    best_error = 10     # Keep track of the best error so far \n",
    "    # Note: Since error is always <= 1, we should intialize it with something larger than 1.\n",
    "\n",
    "    # Convert to float to make sure error gets computed correctly.\n",
    "    num_data_points = float(len(data))  \n",
    "    \n",
    "    # Loop through each feature to consider splitting on that feature\n",
    "    for feature in features:\n",
    "        \n",
    "        # The left split will have all data points where the feature value is 0\n",
    "        left_split = data[data[feature] == 0]\n",
    "        \n",
    "        # The right split will have all data points where the feature value is 1\n",
    "        ## YOUR CODE HERE\n",
    "        right_split =  data[data[feature] == 1]\n",
    "            \n",
    "        # Calculate the number of misclassified examples in the left split.\n",
    "        # Remember that we implemented a function for this! (It was called intermediate_node_num_mistakes)\n",
    "        # YOUR CODE HERE\n",
    "        left_mistakes = intermediate_node_num_mistakes(left_split[target])            \n",
    "\n",
    "        # Calculate the number of misclassified examples in the right split.\n",
    "        ## YOUR CODE HERE\n",
    "        right_mistakes = intermediate_node_num_mistakes(right_split[target]) \n",
    "            \n",
    "        # Compute the classification error of this split.\n",
    "        # Error = (# of mistakes (left) + # of mistakes (right)) / (# of data points)\n",
    "        ## YOUR CODE HERE\n",
    "        error = (left_mistakes + right_mistakes) / len(data)\n",
    "        \n",
    "        #print(\"left_mistakes\\t\", left_mistakes, \" right_mistakes\\t\", right_mistakes, \" error\\t\", error, \" best_feature\\t\", best_feature)\n",
    "\n",
    "        # If this is the best error we have found so far, store the feature as best_feature and the error as best_error\n",
    "        ## YOUR CODE HERE\n",
    "        if error < best_error:\n",
    "            best_feature = feature\n",
    "            best_error = error\n",
    "        \n",
    "    \n",
    "    return best_feature # Return the best feature we found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test your `best_splitting_feature` function, run the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_mistakes\t 14876  right_mistakes\t 1258  error\t 0.4334300451321728  best_feature\t None\n",
      "left_mistakes\t 12725  right_mistakes\t 4343  error\t 0.45852138405329895  best_feature\t grade.A\n",
      "left_mistakes\t 13562  right_mistakes\t 4498  error\t 0.485170857511283  best_feature\t grade.A\n",
      "left_mistakes\t 14400  right_mistakes\t 2683  error\t 0.4589243498817967  best_feature\t grade.A\n",
      "left_mistakes\t 16168  right_mistakes\t 1101  error\t 0.46392112615516873  best_feature\t grade.A\n",
      "left_mistakes\t 17226  right_mistakes\t 462  error\t 0.475177304964539  best_feature\t grade.A\n",
      "left_mistakes\t 18149  right_mistakes\t 109  error\t 0.4904900064474533  best_feature\t grade.A\n",
      "left_mistakes\t 3221  right_mistakes\t 12474  error\t 0.4216365785514722  best_feature\t grade.A\n",
      "left_mistakes\t 12474  right_mistakes\t 3221  error\t 0.4216365785514722  best_feature\t term. 36 months\n",
      "left_mistakes\t 9383  right_mistakes\t 8013  error\t 0.4673329035031163  best_feature\t term. 36 months\n",
      "left_mistakes\t 18443  right_mistakes\t 28  error\t 0.4962121212121212  best_feature\t term. 36 months\n",
      "left_mistakes\t 16916  right_mistakes\t 1515  error\t 0.49513754566946055  best_feature\t term. 36 months\n",
      "left_mistakes\t 9606  right_mistakes\t 7840  error\t 0.46867612293144206  best_feature\t term. 36 months\n",
      "left_mistakes\t 17190  right_mistakes\t 1286  error\t 0.4963464431549538  best_feature\t term. 36 months\n",
      "left_mistakes\t 13417  right_mistakes\t 5059  error\t 0.4963464431549538  best_feature\t term. 36 months\n",
      "left_mistakes\t 16766  right_mistakes\t 1710  error\t 0.4963464431549538  best_feature\t term. 36 months\n",
      "left_mistakes\t 16967  right_mistakes\t 1509  error\t 0.4963464431549538  best_feature\t term. 36 months\n",
      "left_mistakes\t 17258  right_mistakes\t 1218  error\t 0.4963464431549538  best_feature\t term. 36 months\n",
      "left_mistakes\t 17041  right_mistakes\t 1435  error\t 0.4963464431549538  best_feature\t term. 36 months\n",
      "left_mistakes\t 17285  right_mistakes\t 1128  error\t 0.4946539866752633  best_feature\t term. 36 months\n",
      "left_mistakes\t 17427  right_mistakes\t 979  error\t 0.49446593595529764  best_feature\t term. 36 months\n",
      "left_mistakes\t 17665  right_mistakes\t 806  error\t 0.4962121212121212  best_feature\t term. 36 months\n",
      "left_mistakes\t 17811  right_mistakes\t 665  error\t 0.4963464431549538  best_feature\t term. 36 months\n",
      "left_mistakes\t 16818  right_mistakes\t 1658  error\t 0.4963464431549538  best_feature\t term. 36 months\n",
      "left_mistakes\t 17591  right_mistakes\t 558  error\t 0.487561788093703  best_feature\t term. 36 months\n",
      "Test passed!\n"
     ]
    }
   ],
   "source": [
    "if best_splitting_feature(train_data, features, 'safe_loans') == 'term. 36 months':\n",
    "    print('Test passed!')\n",
    "else:\n",
    "    print('Test failed... try again!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the tree\n",
    "\n",
    "With the above functions implemented correctly, we are now ready to build our decision tree. Each node in the decision tree is represented as a dictionary which contains the following keys and possible values:\n",
    "\n",
    "    { \n",
    "       'is_leaf'            : True/False.\n",
    "       'prediction'         : Prediction at the leaf node.\n",
    "       'left'               : (dictionary corresponding to the left tree).\n",
    "       'right'              : (dictionary corresponding to the right tree).\n",
    "       'splitting_feature'  : The feature that this node splits on.\n",
    "    }\n",
    "\n",
    "First, we will write a function that creates a leaf node given a set of target values. Fill in the places where you find `## YOUR CODE HERE`. There are **three** places in this function for you to fill in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_leaf(target_values):\n",
    "    \n",
    "    # Create a leaf node\n",
    "    leaf = {\n",
    "        'splitting_feature' : None,\n",
    "        'left' : None,\n",
    "        'right' : None,\n",
    "        'is_leaf': True    \n",
    "    }   ## YOUR CODE HERE\n",
    "    \n",
    "    # Count the number of data points that are +1 and -1 in this node.\n",
    "    num_ones = len(target_values[target_values == +1])\n",
    "    num_minus_ones = len(target_values[target_values == -1])\n",
    "    \n",
    "    # For the leaf node, set the prediction to be the majority class.\n",
    "    # Store the predicted class (1 or -1) in leaf['prediction']\n",
    "    if num_ones > num_minus_ones:\n",
    "        leaf['prediction'] = +1         ## YOUR CODE HERE\n",
    "    else:\n",
    "        leaf['prediction'] = -1         ## YOUR CODE HERE\n",
    "        \n",
    "    # Return the leaf node        \n",
    "    return leaf "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have provided a function that learns the decision tree recursively and implements 3 stopping conditions:\n",
    "1. **Stopping condition 1:** All data points in a node are from the same class.\n",
    "2. **Stopping condition 2:** No more features to split on.\n",
    "3. **Additional stopping condition:** In addition to the above two stopping conditions covered in lecture, in this assignment we will also consider a stopping condition based on the **max_depth** of the tree. By not letting the tree grow too deep, we will save computational effort in the learning process. \n",
    "\n",
    "Now, we will write down the skeleton of the learning algorithm. Fill in the places where you find `## YOUR CODE HERE`. There are **seven** places in this function for you to fill in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree_create(data, features, target, current_depth = 0, max_depth = 10):\n",
    "    remaining_features = features[:] # Make a copy of the features.\n",
    "    \n",
    "    target_values = data[target]\n",
    "    print(\"--------------------------------------------------------------------\")\n",
    "    print(\"Subtree, depth = %s (%s data points).\" % (current_depth, len(target_values)))\n",
    "\n",
    "\n",
    "    # Stopping condition 1\n",
    "    # (Check if there are mistakes at current node.\n",
    "    # Recall you wrote a function intermediate_node_num_mistakes to compute this.)\n",
    "    if intermediate_node_num_mistakes(target_values) == 0:  ## YOUR CODE HERE\n",
    "        print(\"Stopping condition 1 reached.\")\n",
    "        # If not mistakes at current node, make current node a leaf node\n",
    "        return create_leaf(target_values)\n",
    "    \n",
    "    # Stopping condition 2 (check if there are remaining features to consider splitting on)\n",
    "    if remaining_features == []:   ## YOUR CODE HERE\n",
    "        print(\"Stopping condition 2 reached.\")\n",
    "        # If there are no remaining features to consider, make current node a leaf node\n",
    "        return create_leaf(target_values)    \n",
    "    \n",
    "    # Additional stopping condition (limit tree depth)\n",
    "    if current_depth >= max_depth:  ## YOUR CODE HERE\n",
    "        print(\"Reached maximum depth. Stopping for now.\")\n",
    "        # If the max tree depth has been reached, make current node a leaf node\n",
    "        return create_leaf(target_values)\n",
    "\n",
    "    # Find the best splitting feature (recall the function best_splitting_feature implemented above)\n",
    "    ## YOUR CODE HERE\n",
    "    splitting_feature = best_splitting_feature(data, remaining_features, target)\n",
    "\n",
    "    \n",
    "    # Split on the best feature that we found. \n",
    "    left_split = data[data[splitting_feature] == 0]\n",
    "    right_split = data[data[splitting_feature] == 1]\n",
    "    remaining_features.remove(splitting_feature)\n",
    "    print(\"Split on feature %s. (%s, %s)\" % (\\\n",
    "                      splitting_feature, len(left_split), len(right_split)))\n",
    "    \n",
    "    # Create a leaf node if the split is \"perfect\"\n",
    "    if len(left_split) == len(data):\n",
    "        print(\"Creating leaf node.\")\n",
    "        return create_leaf(left_split[target])\n",
    "    if len(right_split) == len(data):\n",
    "        print(\"Creating leaf node.\")\n",
    "        ## YOUR CODE HERE\n",
    "        return create_leaf(right_split[target])\n",
    "\n",
    "        \n",
    "    # Repeat (recurse) on left and right subtrees\n",
    "    left_tree = decision_tree_create(left_split, remaining_features, target, current_depth + 1, max_depth)        \n",
    "    ## YOUR CODE HERE\n",
    "    right_tree = decision_tree_create(right_split, remaining_features, target, current_depth + 1, max_depth)        \n",
    "\n",
    "    return {'is_leaf'          : False, \n",
    "            'prediction'       : None,\n",
    "            'splitting_feature': splitting_feature,\n",
    "            'left'             : left_tree, \n",
    "            'right'            : right_tree}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a recursive function to count the nodes in your tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_nodes(tree):\n",
    "    if tree['is_leaf']:\n",
    "        return 1\n",
    "    return 1 + count_nodes(tree['left']) + count_nodes(tree['right'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following test code to check your implementation. Make sure you get **'Test passed'** before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 0 (37224 data points).\n",
      "left_mistakes\t 14876  right_mistakes\t 1258  error\t 0.4334300451321728  best_feature\t None\n",
      "left_mistakes\t 12725  right_mistakes\t 4343  error\t 0.45852138405329895  best_feature\t grade.A\n",
      "left_mistakes\t 13562  right_mistakes\t 4498  error\t 0.485170857511283  best_feature\t grade.A\n",
      "left_mistakes\t 14400  right_mistakes\t 2683  error\t 0.4589243498817967  best_feature\t grade.A\n",
      "left_mistakes\t 16168  right_mistakes\t 1101  error\t 0.46392112615516873  best_feature\t grade.A\n",
      "left_mistakes\t 17226  right_mistakes\t 462  error\t 0.475177304964539  best_feature\t grade.A\n",
      "left_mistakes\t 18149  right_mistakes\t 109  error\t 0.4904900064474533  best_feature\t grade.A\n",
      "left_mistakes\t 3221  right_mistakes\t 12474  error\t 0.4216365785514722  best_feature\t grade.A\n",
      "left_mistakes\t 12474  right_mistakes\t 3221  error\t 0.4216365785514722  best_feature\t term. 36 months\n",
      "left_mistakes\t 9383  right_mistakes\t 8013  error\t 0.4673329035031163  best_feature\t term. 36 months\n",
      "left_mistakes\t 18443  right_mistakes\t 28  error\t 0.4962121212121212  best_feature\t term. 36 months\n",
      "left_mistakes\t 16916  right_mistakes\t 1515  error\t 0.49513754566946055  best_feature\t term. 36 months\n",
      "left_mistakes\t 9606  right_mistakes\t 7840  error\t 0.46867612293144206  best_feature\t term. 36 months\n",
      "left_mistakes\t 17190  right_mistakes\t 1286  error\t 0.4963464431549538  best_feature\t term. 36 months\n",
      "left_mistakes\t 13417  right_mistakes\t 5059  error\t 0.4963464431549538  best_feature\t term. 36 months\n",
      "left_mistakes\t 16766  right_mistakes\t 1710  error\t 0.4963464431549538  best_feature\t term. 36 months\n",
      "left_mistakes\t 16967  right_mistakes\t 1509  error\t 0.4963464431549538  best_feature\t term. 36 months\n",
      "left_mistakes\t 17258  right_mistakes\t 1218  error\t 0.4963464431549538  best_feature\t term. 36 months\n",
      "left_mistakes\t 17041  right_mistakes\t 1435  error\t 0.4963464431549538  best_feature\t term. 36 months\n",
      "left_mistakes\t 17285  right_mistakes\t 1128  error\t 0.4946539866752633  best_feature\t term. 36 months\n",
      "left_mistakes\t 17427  right_mistakes\t 979  error\t 0.49446593595529764  best_feature\t term. 36 months\n",
      "left_mistakes\t 17665  right_mistakes\t 806  error\t 0.4962121212121212  best_feature\t term. 36 months\n",
      "left_mistakes\t 17811  right_mistakes\t 665  error\t 0.4963464431549538  best_feature\t term. 36 months\n",
      "left_mistakes\t 16818  right_mistakes\t 1658  error\t 0.4963464431549538  best_feature\t term. 36 months\n",
      "left_mistakes\t 17591  right_mistakes\t 558  error\t 0.487561788093703  best_feature\t term. 36 months\n",
      "Split on feature term. 36 months. (9223, 28001)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (9223 data points).\n",
      "left_mistakes\t 3159  right_mistakes\t 39  error\t 0.34674184104955  best_feature\t None\n",
      "left_mistakes\t 2760  right_mistakes\t 461  error\t 0.34923560663558495  best_feature\t grade.A\n",
      "left_mistakes\t 2307  right_mistakes\t 914  error\t 0.34923560663558495  best_feature\t grade.A\n",
      "left_mistakes\t 2498  right_mistakes\t 723  error\t 0.34923560663558495  best_feature\t grade.A\n",
      "left_mistakes\t 2597  right_mistakes\t 624  error\t 0.34923560663558495  best_feature\t grade.A\n",
      "left_mistakes\t 2867  right_mistakes\t 354  error\t 0.34923560663558495  best_feature\t grade.A\n",
      "left_mistakes\t 3138  right_mistakes\t 83  error\t 0.34923560663558495  best_feature\t grade.A\n",
      "left_mistakes\t 0  right_mistakes\t 3221  error\t 0.34923560663558495  best_feature\t grade.A\n",
      "left_mistakes\t 1254  right_mistakes\t 1967  error\t 0.34923560663558495  best_feature\t grade.A\n",
      "left_mistakes\t 3220  right_mistakes\t 1  error\t 0.34923560663558495  best_feature\t grade.A\n",
      "left_mistakes\t 2982  right_mistakes\t 239  error\t 0.34923560663558495  best_feature\t grade.A\n",
      "left_mistakes\t 2207  right_mistakes\t 1014  error\t 0.34923560663558495  best_feature\t grade.A\n",
      "left_mistakes\t 3045  right_mistakes\t 176  error\t 0.34923560663558495  best_feature\t grade.A\n",
      "left_mistakes\t 2082  right_mistakes\t 1139  error\t 0.34923560663558495  best_feature\t grade.A\n",
      "left_mistakes\t 2942  right_mistakes\t 279  error\t 0.34923560663558495  best_feature\t grade.A\n",
      "left_mistakes\t 2984  right_mistakes\t 237  error\t 0.34923560663558495  best_feature\t grade.A\n",
      "left_mistakes\t 3013  right_mistakes\t 208  error\t 0.34923560663558495  best_feature\t grade.A\n",
      "left_mistakes\t 2964  right_mistakes\t 257  error\t 0.34923560663558495  best_feature\t grade.A\n",
      "left_mistakes\t 3048  right_mistakes\t 173  error\t 0.34923560663558495  best_feature\t grade.A\n",
      "left_mistakes\t 3030  right_mistakes\t 191  error\t 0.34923560663558495  best_feature\t grade.A\n",
      "left_mistakes\t 3073  right_mistakes\t 148  error\t 0.34923560663558495  best_feature\t grade.A\n",
      "left_mistakes\t 3096  right_mistakes\t 125  error\t 0.34923560663558495  best_feature\t grade.A\n",
      "left_mistakes\t 2988  right_mistakes\t 233  error\t 0.34923560663558495  best_feature\t grade.A\n",
      "left_mistakes\t 3166  right_mistakes\t 55  error\t 0.34923560663558495  best_feature\t grade.A\n",
      "Split on feature grade.A. (9122, 101)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (9122 data points).\n",
      "left_mistakes\t 2698  right_mistakes\t 461  error\t 0.34630563472922604  best_feature\t None\n",
      "left_mistakes\t 2245  right_mistakes\t 914  error\t 0.34630563472922604  best_feature\t grade.B\n",
      "left_mistakes\t 2436  right_mistakes\t 723  error\t 0.34630563472922604  best_feature\t grade.B\n",
      "left_mistakes\t 2535  right_mistakes\t 624  error\t 0.34630563472922604  best_feature\t grade.B\n",
      "left_mistakes\t 2805  right_mistakes\t 354  error\t 0.34630563472922604  best_feature\t grade.B\n",
      "left_mistakes\t 3076  right_mistakes\t 83  error\t 0.34630563472922604  best_feature\t grade.B\n",
      "left_mistakes\t 0  right_mistakes\t 3159  error\t 0.34630563472922604  best_feature\t grade.B\n",
      "left_mistakes\t 1234  right_mistakes\t 1925  error\t 0.34630563472922604  best_feature\t grade.B\n",
      "left_mistakes\t 3158  right_mistakes\t 1  error\t 0.34630563472922604  best_feature\t grade.B\n",
      "left_mistakes\t 2927  right_mistakes\t 232  error\t 0.34630563472922604  best_feature\t grade.B\n",
      "left_mistakes\t 2158  right_mistakes\t 1001  error\t 0.34630563472922604  best_feature\t grade.B\n",
      "left_mistakes\t 2985  right_mistakes\t 174  error\t 0.34630563472922604  best_feature\t grade.B\n",
      "left_mistakes\t 2039  right_mistakes\t 1120  error\t 0.34630563472922604  best_feature\t grade.B\n",
      "left_mistakes\t 2886  right_mistakes\t 273  error\t 0.34630563472922604  best_feature\t grade.B\n",
      "left_mistakes\t 2926  right_mistakes\t 233  error\t 0.34630563472922604  best_feature\t grade.B\n",
      "left_mistakes\t 2955  right_mistakes\t 204  error\t 0.34630563472922604  best_feature\t grade.B\n",
      "left_mistakes\t 2906  right_mistakes\t 253  error\t 0.34630563472922604  best_feature\t grade.B\n",
      "left_mistakes\t 2991  right_mistakes\t 168  error\t 0.34630563472922604  best_feature\t grade.B\n",
      "left_mistakes\t 2972  right_mistakes\t 187  error\t 0.34630563472922604  best_feature\t grade.B\n",
      "left_mistakes\t 3018  right_mistakes\t 141  error\t 0.34630563472922604  best_feature\t grade.B\n",
      "left_mistakes\t 3035  right_mistakes\t 124  error\t 0.34630563472922604  best_feature\t grade.B\n",
      "left_mistakes\t 2931  right_mistakes\t 228  error\t 0.34630563472922604  best_feature\t grade.B\n",
      "left_mistakes\t 3105  right_mistakes\t 54  error\t 0.34630563472922604  best_feature\t grade.B\n",
      "Split on feature grade.B. (8074, 1048)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (8074 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (1048 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (101 data points).\n",
      "left_mistakes\t 39  right_mistakes\t 0  error\t 0.38613861386138615  best_feature\t None\n",
      "left_mistakes\t 39  right_mistakes\t 0  error\t 0.38613861386138615  best_feature\t grade.B\n",
      "left_mistakes\t 39  right_mistakes\t 0  error\t 0.38613861386138615  best_feature\t grade.B\n",
      "left_mistakes\t 39  right_mistakes\t 0  error\t 0.38613861386138615  best_feature\t grade.B\n",
      "left_mistakes\t 39  right_mistakes\t 0  error\t 0.38613861386138615  best_feature\t grade.B\n",
      "left_mistakes\t 39  right_mistakes\t 0  error\t 0.38613861386138615  best_feature\t grade.B\n",
      "left_mistakes\t 0  right_mistakes\t 39  error\t 0.38613861386138615  best_feature\t grade.B\n",
      "left_mistakes\t 16  right_mistakes\t 23  error\t 0.38613861386138615  best_feature\t grade.B\n",
      "left_mistakes\t 39  right_mistakes\t 0  error\t 0.38613861386138615  best_feature\t grade.B\n",
      "left_mistakes\t 36  right_mistakes\t 3  error\t 0.38613861386138615  best_feature\t grade.B\n",
      "left_mistakes\t 26  right_mistakes\t 13  error\t 0.38613861386138615  best_feature\t grade.B\n",
      "left_mistakes\t 37  right_mistakes\t 2  error\t 0.38613861386138615  best_feature\t grade.B\n",
      "left_mistakes\t 27  right_mistakes\t 12  error\t 0.38613861386138615  best_feature\t grade.B\n",
      "left_mistakes\t 37  right_mistakes\t 2  error\t 0.38613861386138615  best_feature\t grade.B\n",
      "left_mistakes\t 36  right_mistakes\t 3  error\t 0.38613861386138615  best_feature\t grade.B\n",
      "left_mistakes\t 37  right_mistakes\t 2  error\t 0.38613861386138615  best_feature\t grade.B\n",
      "left_mistakes\t 35  right_mistakes\t 4  error\t 0.38613861386138615  best_feature\t grade.B\n",
      "left_mistakes\t 36  right_mistakes\t 3  error\t 0.38613861386138615  best_feature\t grade.B\n",
      "left_mistakes\t 39  right_mistakes\t 0  error\t 0.38613861386138615  best_feature\t grade.B\n",
      "left_mistakes\t 38  right_mistakes\t 1  error\t 0.38613861386138615  best_feature\t grade.B\n",
      "left_mistakes\t 39  right_mistakes\t 0  error\t 0.38613861386138615  best_feature\t grade.B\n",
      "left_mistakes\t 33  right_mistakes\t 5  error\t 0.37623762376237624  best_feature\t grade.B\n",
      "left_mistakes\t 35  right_mistakes\t 1  error\t 0.3564356435643564  best_feature\t emp_length.< 1 year\n",
      "Split on feature emp_length.n/a. (96, 5)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (96 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (5 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (28001 data points).\n",
      "left_mistakes\t 11255  right_mistakes\t 1219  error\t 0.4454840898539338  best_feature\t None\n",
      "left_mistakes\t 8718  right_mistakes\t 3756  error\t 0.4454840898539338  best_feature\t grade.A\n",
      "left_mistakes\t 8836  right_mistakes\t 3584  error\t 0.4435555873004536  best_feature\t grade.A\n",
      "left_mistakes\t 9733  right_mistakes\t 1960  error\t 0.4175922288489697  best_feature\t grade.C\n",
      "left_mistakes\t 11675  right_mistakes\t 477  error\t 0.43398450055355164  best_feature\t grade.D\n",
      "left_mistakes\t 12224  right_mistakes\t 108  error\t 0.44041284239848577  best_feature\t grade.D\n",
      "left_mistakes\t 12403  right_mistakes\t 26  error\t 0.4438770043927003  best_feature\t grade.D\n",
      "left_mistakes\t 12474  right_mistakes\t 0  error\t 0.4454840898539338  best_feature\t grade.D\n",
      "left_mistakes\t 7623  right_mistakes\t 4851  error\t 0.4454840898539338  best_feature\t grade.D\n",
      "left_mistakes\t 12443  right_mistakes\t 27  error\t 0.4453412378129353  best_feature\t grade.D\n",
      "left_mistakes\t 11392  right_mistakes\t 1082  error\t 0.4454840898539338  best_feature\t grade.D\n",
      "left_mistakes\t 5964  right_mistakes\t 6510  error\t 0.4454840898539338  best_feature\t grade.D\n",
      "left_mistakes\t 11536  right_mistakes\t 938  error\t 0.4454840898539338  best_feature\t grade.D\n",
      "left_mistakes\t 9391  right_mistakes\t 3083  error\t 0.4454840898539338  best_feature\t grade.D\n",
      "left_mistakes\t 11256  right_mistakes\t 1218  error\t 0.4454840898539338  best_feature\t grade.D\n",
      "left_mistakes\t 11409  right_mistakes\t 1065  error\t 0.4454840898539338  best_feature\t grade.D\n",
      "left_mistakes\t 11624  right_mistakes\t 850  error\t 0.4454840898539338  best_feature\t grade.D\n",
      "left_mistakes\t 11497  right_mistakes\t 977  error\t 0.4454840898539338  best_feature\t grade.D\n",
      "left_mistakes\t 11668  right_mistakes\t 806  error\t 0.4454840898539338  best_feature\t grade.D\n",
      "left_mistakes\t 11785  right_mistakes\t 689  error\t 0.4454840898539338  best_feature\t grade.D\n",
      "left_mistakes\t 11943  right_mistakes\t 531  error\t 0.4454840898539338  best_feature\t grade.D\n",
      "left_mistakes\t 12072  right_mistakes\t 402  error\t 0.4454840898539338  best_feature\t grade.D\n",
      "left_mistakes\t 11273  right_mistakes\t 1201  error\t 0.4454840898539338  best_feature\t grade.D\n",
      "left_mistakes\t 11760  right_mistakes\t 503  error\t 0.43794864469126105  best_feature\t grade.D\n",
      "Split on feature grade.D. (23300, 4701)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (23300 data points).\n",
      "left_mistakes\t 8514  right_mistakes\t 1219  error\t 0.417725321888412  best_feature\t None\n",
      "left_mistakes\t 5977  right_mistakes\t 3756  error\t 0.417725321888412  best_feature\t grade.A\n",
      "left_mistakes\t 6095  right_mistakes\t 3584  error\t 0.4154077253218884  best_feature\t grade.A\n",
      "left_mistakes\t 8934  right_mistakes\t 477  error\t 0.4039055793991416  best_feature\t grade.C\n",
      "left_mistakes\t 9483  right_mistakes\t 108  error\t 0.41163090128755364  best_feature\t grade.E\n",
      "left_mistakes\t 9662  right_mistakes\t 26  error\t 0.415793991416309  best_feature\t grade.E\n",
      "left_mistakes\t 9733  right_mistakes\t 0  error\t 0.417725321888412  best_feature\t grade.E\n",
      "left_mistakes\t 5755  right_mistakes\t 3978  error\t 0.417725321888412  best_feature\t grade.E\n",
      "left_mistakes\t 9709  right_mistakes\t 24  error\t 0.417725321888412  best_feature\t grade.E\n",
      "left_mistakes\t 8907  right_mistakes\t 826  error\t 0.417725321888412  best_feature\t grade.E\n",
      "left_mistakes\t 4828  right_mistakes\t 4905  error\t 0.417725321888412  best_feature\t grade.E\n",
      "left_mistakes\t 9010  right_mistakes\t 723  error\t 0.417725321888412  best_feature\t grade.E\n",
      "left_mistakes\t 7315  right_mistakes\t 2418  error\t 0.417725321888412  best_feature\t grade.E\n",
      "left_mistakes\t 8789  right_mistakes\t 944  error\t 0.417725321888412  best_feature\t grade.E\n",
      "left_mistakes\t 8913  right_mistakes\t 820  error\t 0.417725321888412  best_feature\t grade.E\n",
      "left_mistakes\t 9073  right_mistakes\t 660  error\t 0.417725321888412  best_feature\t grade.E\n",
      "left_mistakes\t 8960  right_mistakes\t 773  error\t 0.417725321888412  best_feature\t grade.E\n",
      "left_mistakes\t 9113  right_mistakes\t 620  error\t 0.417725321888412  best_feature\t grade.E\n",
      "left_mistakes\t 9204  right_mistakes\t 529  error\t 0.417725321888412  best_feature\t grade.E\n",
      "left_mistakes\t 9321  right_mistakes\t 412  error\t 0.417725321888412  best_feature\t grade.E\n",
      "left_mistakes\t 9411  right_mistakes\t 322  error\t 0.417725321888412  best_feature\t grade.E\n",
      "left_mistakes\t 8793  right_mistakes\t 940  error\t 0.417725321888412  best_feature\t grade.E\n",
      "left_mistakes\t 9161  right_mistakes\t 438  error\t 0.4119742489270386  best_feature\t grade.E\n",
      "Split on feature grade.E. (22024, 1276)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (22024 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (1276 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (4701 data points).\n",
      "left_mistakes\t 1960  right_mistakes\t 0  error\t 0.4169325675388215  best_feature\t None\n",
      "left_mistakes\t 1960  right_mistakes\t 0  error\t 0.4169325675388215  best_feature\t grade.A\n",
      "left_mistakes\t 1960  right_mistakes\t 0  error\t 0.4169325675388215  best_feature\t grade.A\n",
      "left_mistakes\t 1960  right_mistakes\t 0  error\t 0.4169325675388215  best_feature\t grade.A\n",
      "left_mistakes\t 1960  right_mistakes\t 0  error\t 0.4169325675388215  best_feature\t grade.A\n",
      "left_mistakes\t 1960  right_mistakes\t 0  error\t 0.4169325675388215  best_feature\t grade.A\n",
      "left_mistakes\t 1960  right_mistakes\t 0  error\t 0.4169325675388215  best_feature\t grade.A\n",
      "left_mistakes\t 1179  right_mistakes\t 781  error\t 0.4169325675388215  best_feature\t grade.A\n",
      "left_mistakes\t 1957  right_mistakes\t 3  error\t 0.4169325675388215  best_feature\t grade.A\n",
      "left_mistakes\t 1812  right_mistakes\t 148  error\t 0.4169325675388215  best_feature\t grade.A\n",
      "left_mistakes\t 932  right_mistakes\t 1028  error\t 0.4169325675388215  best_feature\t grade.A\n",
      "left_mistakes\t 1816  right_mistakes\t 144  error\t 0.4169325675388215  best_feature\t grade.A\n",
      "left_mistakes\t 1456  right_mistakes\t 504  error\t 0.4169325675388215  best_feature\t grade.A\n",
      "left_mistakes\t 1755  right_mistakes\t 205  error\t 0.4169325675388215  best_feature\t grade.A\n",
      "left_mistakes\t 1778  right_mistakes\t 182  error\t 0.4169325675388215  best_feature\t grade.A\n",
      "left_mistakes\t 1823  right_mistakes\t 137  error\t 0.4169325675388215  best_feature\t grade.A\n",
      "left_mistakes\t 1797  right_mistakes\t 163  error\t 0.4169325675388215  best_feature\t grade.A\n",
      "left_mistakes\t 1854  right_mistakes\t 106  error\t 0.4169325675388215  best_feature\t grade.A\n",
      "left_mistakes\t 1843  right_mistakes\t 117  error\t 0.4169325675388215  best_feature\t grade.A\n",
      "left_mistakes\t 1876  right_mistakes\t 84  error\t 0.4169325675388215  best_feature\t grade.A\n",
      "left_mistakes\t 1888  right_mistakes\t 72  error\t 0.4169325675388215  best_feature\t grade.A\n",
      "left_mistakes\t 1779  right_mistakes\t 181  error\t 0.4169325675388215  best_feature\t grade.A\n",
      "left_mistakes\t 1895  right_mistakes\t 65  error\t 0.4169325675388215  best_feature\t grade.A\n",
      "Split on feature grade.A. (4701, 0)\n",
      "Creating leaf node.\n",
      "Test passed!\n"
     ]
    }
   ],
   "source": [
    "small_data_decision_tree = decision_tree_create(train_data, features, 'safe_loans', max_depth = 3)\n",
    "if count_nodes(small_data_decision_tree) == 13:\n",
    "    print('Test passed!')\n",
    "else:\n",
    "    print('Test failed... try again!')\n",
    "    print('Number of nodes found                :', count_nodes(small_data_decision_tree))\n",
    "    print('Number of nodes that should be there : 13' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the tree!\n",
    "\n",
    "Now that all the tests are passing, we will train a tree model on the **train_data**. Limit the depth to 6 (**max_depth = 6**) to make sure the algorithm doesn't run for too long. Call this tree **my_decision_tree**. \n",
    "\n",
    "**Warning**: This code block may take 1-2 minutes to learn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 0 (37224 data points).\n",
      "left_mistakes\t 14876  right_mistakes\t 1258  error\t 0.4334300451321728  best_feature\t None\n",
      "left_mistakes\t 12725  right_mistakes\t 4343  error\t 0.45852138405329895  best_feature\t grade.A\n",
      "left_mistakes\t 13562  right_mistakes\t 4498  error\t 0.485170857511283  best_feature\t grade.A\n",
      "left_mistakes\t 14400  right_mistakes\t 2683  error\t 0.4589243498817967  best_feature\t grade.A\n",
      "left_mistakes\t 16168  right_mistakes\t 1101  error\t 0.46392112615516873  best_feature\t grade.A\n",
      "left_mistakes\t 17226  right_mistakes\t 462  error\t 0.475177304964539  best_feature\t grade.A\n",
      "left_mistakes\t 18149  right_mistakes\t 109  error\t 0.4904900064474533  best_feature\t grade.A\n",
      "left_mistakes\t 3221  right_mistakes\t 12474  error\t 0.4216365785514722  best_feature\t grade.A\n",
      "left_mistakes\t 12474  right_mistakes\t 3221  error\t 0.4216365785514722  best_feature\t term. 36 months\n",
      "left_mistakes\t 9383  right_mistakes\t 8013  error\t 0.4673329035031163  best_feature\t term. 36 months\n",
      "left_mistakes\t 18443  right_mistakes\t 28  error\t 0.4962121212121212  best_feature\t term. 36 months\n",
      "left_mistakes\t 16916  right_mistakes\t 1515  error\t 0.49513754566946055  best_feature\t term. 36 months\n",
      "left_mistakes\t 9606  right_mistakes\t 7840  error\t 0.46867612293144206  best_feature\t term. 36 months\n",
      "left_mistakes\t 17190  right_mistakes\t 1286  error\t 0.4963464431549538  best_feature\t term. 36 months\n",
      "left_mistakes\t 13417  right_mistakes\t 5059  error\t 0.4963464431549538  best_feature\t term. 36 months\n",
      "left_mistakes\t 16766  right_mistakes\t 1710  error\t 0.4963464431549538  best_feature\t term. 36 months\n",
      "left_mistakes\t 16967  right_mistakes\t 1509  error\t 0.4963464431549538  best_feature\t term. 36 months\n",
      "left_mistakes\t 17258  right_mistakes\t 1218  error\t 0.4963464431549538  best_feature\t term. 36 months\n",
      "left_mistakes\t 17041  right_mistakes\t 1435  error\t 0.4963464431549538  best_feature\t term. 36 months\n",
      "left_mistakes\t 17285  right_mistakes\t 1128  error\t 0.4946539866752633  best_feature\t term. 36 months\n",
      "left_mistakes\t 17427  right_mistakes\t 979  error\t 0.49446593595529764  best_feature\t term. 36 months\n",
      "left_mistakes\t 17665  right_mistakes\t 806  error\t 0.4962121212121212  best_feature\t term. 36 months\n",
      "left_mistakes\t 17811  right_mistakes\t 665  error\t 0.4963464431549538  best_feature\t term. 36 months\n",
      "left_mistakes\t 16818  right_mistakes\t 1658  error\t 0.4963464431549538  best_feature\t term. 36 months\n",
      "left_mistakes\t 17591  right_mistakes\t 558  error\t 0.487561788093703  best_feature\t term. 36 months\n",
      "Split on feature term. 36 months. (9223, 28001)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (9223 data points).\n",
      "left_mistakes\t 3159  right_mistakes\t 39  error\t 0.34674184104955  best_feature\t None\n",
      "left_mistakes\t 2760  right_mistakes\t 461  error\t 0.34923560663558495  best_feature\t grade.A\n",
      "left_mistakes\t 2307  right_mistakes\t 914  error\t 0.34923560663558495  best_feature\t grade.A\n",
      "left_mistakes\t 2498  right_mistakes\t 723  error\t 0.34923560663558495  best_feature\t grade.A\n",
      "left_mistakes\t 2597  right_mistakes\t 624  error\t 0.34923560663558495  best_feature\t grade.A\n",
      "left_mistakes\t 2867  right_mistakes\t 354  error\t 0.34923560663558495  best_feature\t grade.A\n",
      "left_mistakes\t 3138  right_mistakes\t 83  error\t 0.34923560663558495  best_feature\t grade.A\n",
      "left_mistakes\t 0  right_mistakes\t 3221  error\t 0.34923560663558495  best_feature\t grade.A\n",
      "left_mistakes\t 1254  right_mistakes\t 1967  error\t 0.34923560663558495  best_feature\t grade.A\n",
      "left_mistakes\t 3220  right_mistakes\t 1  error\t 0.34923560663558495  best_feature\t grade.A\n",
      "left_mistakes\t 2982  right_mistakes\t 239  error\t 0.34923560663558495  best_feature\t grade.A\n",
      "left_mistakes\t 2207  right_mistakes\t 1014  error\t 0.34923560663558495  best_feature\t grade.A\n",
      "left_mistakes\t 3045  right_mistakes\t 176  error\t 0.34923560663558495  best_feature\t grade.A\n",
      "left_mistakes\t 2082  right_mistakes\t 1139  error\t 0.34923560663558495  best_feature\t grade.A\n",
      "left_mistakes\t 2942  right_mistakes\t 279  error\t 0.34923560663558495  best_feature\t grade.A\n",
      "left_mistakes\t 2984  right_mistakes\t 237  error\t 0.34923560663558495  best_feature\t grade.A\n",
      "left_mistakes\t 3013  right_mistakes\t 208  error\t 0.34923560663558495  best_feature\t grade.A\n",
      "left_mistakes\t 2964  right_mistakes\t 257  error\t 0.34923560663558495  best_feature\t grade.A\n",
      "left_mistakes\t 3048  right_mistakes\t 173  error\t 0.34923560663558495  best_feature\t grade.A\n",
      "left_mistakes\t 3030  right_mistakes\t 191  error\t 0.34923560663558495  best_feature\t grade.A\n",
      "left_mistakes\t 3073  right_mistakes\t 148  error\t 0.34923560663558495  best_feature\t grade.A\n",
      "left_mistakes\t 3096  right_mistakes\t 125  error\t 0.34923560663558495  best_feature\t grade.A\n",
      "left_mistakes\t 2988  right_mistakes\t 233  error\t 0.34923560663558495  best_feature\t grade.A\n",
      "left_mistakes\t 3166  right_mistakes\t 55  error\t 0.34923560663558495  best_feature\t grade.A\n",
      "Split on feature grade.A. (9122, 101)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (9122 data points).\n",
      "left_mistakes\t 2698  right_mistakes\t 461  error\t 0.34630563472922604  best_feature\t None\n",
      "left_mistakes\t 2245  right_mistakes\t 914  error\t 0.34630563472922604  best_feature\t grade.B\n",
      "left_mistakes\t 2436  right_mistakes\t 723  error\t 0.34630563472922604  best_feature\t grade.B\n",
      "left_mistakes\t 2535  right_mistakes\t 624  error\t 0.34630563472922604  best_feature\t grade.B\n",
      "left_mistakes\t 2805  right_mistakes\t 354  error\t 0.34630563472922604  best_feature\t grade.B\n",
      "left_mistakes\t 3076  right_mistakes\t 83  error\t 0.34630563472922604  best_feature\t grade.B\n",
      "left_mistakes\t 0  right_mistakes\t 3159  error\t 0.34630563472922604  best_feature\t grade.B\n",
      "left_mistakes\t 1234  right_mistakes\t 1925  error\t 0.34630563472922604  best_feature\t grade.B\n",
      "left_mistakes\t 3158  right_mistakes\t 1  error\t 0.34630563472922604  best_feature\t grade.B\n",
      "left_mistakes\t 2927  right_mistakes\t 232  error\t 0.34630563472922604  best_feature\t grade.B\n",
      "left_mistakes\t 2158  right_mistakes\t 1001  error\t 0.34630563472922604  best_feature\t grade.B\n",
      "left_mistakes\t 2985  right_mistakes\t 174  error\t 0.34630563472922604  best_feature\t grade.B\n",
      "left_mistakes\t 2039  right_mistakes\t 1120  error\t 0.34630563472922604  best_feature\t grade.B\n",
      "left_mistakes\t 2886  right_mistakes\t 273  error\t 0.34630563472922604  best_feature\t grade.B\n",
      "left_mistakes\t 2926  right_mistakes\t 233  error\t 0.34630563472922604  best_feature\t grade.B\n",
      "left_mistakes\t 2955  right_mistakes\t 204  error\t 0.34630563472922604  best_feature\t grade.B\n",
      "left_mistakes\t 2906  right_mistakes\t 253  error\t 0.34630563472922604  best_feature\t grade.B\n",
      "left_mistakes\t 2991  right_mistakes\t 168  error\t 0.34630563472922604  best_feature\t grade.B\n",
      "left_mistakes\t 2972  right_mistakes\t 187  error\t 0.34630563472922604  best_feature\t grade.B\n",
      "left_mistakes\t 3018  right_mistakes\t 141  error\t 0.34630563472922604  best_feature\t grade.B\n",
      "left_mistakes\t 3035  right_mistakes\t 124  error\t 0.34630563472922604  best_feature\t grade.B\n",
      "left_mistakes\t 2931  right_mistakes\t 228  error\t 0.34630563472922604  best_feature\t grade.B\n",
      "left_mistakes\t 3105  right_mistakes\t 54  error\t 0.34630563472922604  best_feature\t grade.B\n",
      "Split on feature grade.B. (8074, 1048)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (8074 data points).\n",
      "left_mistakes\t 1784  right_mistakes\t 914  error\t 0.33415902898191724  best_feature\t None\n",
      "left_mistakes\t 1975  right_mistakes\t 723  error\t 0.33415902898191724  best_feature\t grade.C\n",
      "left_mistakes\t 2074  right_mistakes\t 624  error\t 0.33415902898191724  best_feature\t grade.C\n",
      "left_mistakes\t 2344  right_mistakes\t 354  error\t 0.33415902898191724  best_feature\t grade.C\n",
      "left_mistakes\t 2615  right_mistakes\t 83  error\t 0.33415902898191724  best_feature\t grade.C\n",
      "left_mistakes\t 0  right_mistakes\t 2698  error\t 0.33415902898191724  best_feature\t grade.C\n",
      "left_mistakes\t 1069  right_mistakes\t 1629  error\t 0.33415902898191724  best_feature\t grade.C\n",
      "left_mistakes\t 2697  right_mistakes\t 1  error\t 0.33415902898191724  best_feature\t grade.C\n",
      "left_mistakes\t 2497  right_mistakes\t 201  error\t 0.33415902898191724  best_feature\t grade.C\n",
      "left_mistakes\t 1831  right_mistakes\t 867  error\t 0.33415902898191724  best_feature\t grade.C\n",
      "left_mistakes\t 2550  right_mistakes\t 148  error\t 0.33415902898191724  best_feature\t grade.C\n",
      "left_mistakes\t 1728  right_mistakes\t 970  error\t 0.33415902898191724  best_feature\t grade.C\n",
      "left_mistakes\t 2467  right_mistakes\t 231  error\t 0.33415902898191724  best_feature\t grade.C\n",
      "left_mistakes\t 2495  right_mistakes\t 203  error\t 0.33415902898191724  best_feature\t grade.C\n",
      "left_mistakes\t 2525  right_mistakes\t 173  error\t 0.33415902898191724  best_feature\t grade.C\n",
      "left_mistakes\t 2486  right_mistakes\t 212  error\t 0.33415902898191724  best_feature\t grade.C\n",
      "left_mistakes\t 2555  right_mistakes\t 143  error\t 0.33415902898191724  best_feature\t grade.C\n",
      "left_mistakes\t 2536  right_mistakes\t 162  error\t 0.33415902898191724  best_feature\t grade.C\n",
      "left_mistakes\t 2577  right_mistakes\t 121  error\t 0.33415902898191724  best_feature\t grade.C\n",
      "left_mistakes\t 2595  right_mistakes\t 103  error\t 0.33415902898191724  best_feature\t grade.C\n",
      "left_mistakes\t 2505  right_mistakes\t 193  error\t 0.33415902898191724  best_feature\t grade.C\n",
      "left_mistakes\t 2659  right_mistakes\t 39  error\t 0.33415902898191724  best_feature\t grade.C\n",
      "Split on feature grade.C. (5884, 2190)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (5884 data points).\n",
      "left_mistakes\t 1061  right_mistakes\t 723  error\t 0.30319510537049627  best_feature\t None\n",
      "left_mistakes\t 1160  right_mistakes\t 624  error\t 0.30319510537049627  best_feature\t grade.D\n",
      "left_mistakes\t 1430  right_mistakes\t 354  error\t 0.30319510537049627  best_feature\t grade.D\n",
      "left_mistakes\t 1701  right_mistakes\t 83  error\t 0.30319510537049627  best_feature\t grade.D\n",
      "left_mistakes\t 0  right_mistakes\t 1784  error\t 0.30319510537049627  best_feature\t grade.D\n",
      "left_mistakes\t 763  right_mistakes\t 1021  error\t 0.30319510537049627  best_feature\t grade.D\n",
      "left_mistakes\t 1783  right_mistakes\t 1  error\t 0.30319510537049627  best_feature\t grade.D\n",
      "left_mistakes\t 1647  right_mistakes\t 137  error\t 0.30319510537049627  best_feature\t grade.D\n",
      "left_mistakes\t 1159  right_mistakes\t 625  error\t 0.30319510537049627  best_feature\t grade.D\n",
      "left_mistakes\t 1682  right_mistakes\t 102  error\t 0.30319510537049627  best_feature\t grade.D\n",
      "left_mistakes\t 1156  right_mistakes\t 628  error\t 0.30319510537049627  best_feature\t grade.D\n",
      "left_mistakes\t 1620  right_mistakes\t 164  error\t 0.30319510537049627  best_feature\t grade.D\n",
      "left_mistakes\t 1648  right_mistakes\t 136  error\t 0.30319510537049627  best_feature\t grade.D\n",
      "left_mistakes\t 1672  right_mistakes\t 112  error\t 0.30319510537049627  best_feature\t grade.D\n",
      "left_mistakes\t 1639  right_mistakes\t 145  error\t 0.30319510537049627  best_feature\t grade.D\n",
      "left_mistakes\t 1694  right_mistakes\t 90  error\t 0.30319510537049627  best_feature\t grade.D\n",
      "left_mistakes\t 1679  right_mistakes\t 105  error\t 0.30319510537049627  best_feature\t grade.D\n",
      "left_mistakes\t 1704  right_mistakes\t 80  error\t 0.30319510537049627  best_feature\t grade.D\n",
      "left_mistakes\t 1711  right_mistakes\t 73  error\t 0.30319510537049627  best_feature\t grade.D\n",
      "left_mistakes\t 1668  right_mistakes\t 116  error\t 0.30319510537049627  best_feature\t grade.D\n",
      "left_mistakes\t 1751  right_mistakes\t 33  error\t 0.30319510537049627  best_feature\t grade.D\n",
      "Split on feature grade.D. (3826, 2058)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (3826 data points).\n",
      "left_mistakes\t 437  right_mistakes\t 624  error\t 0.2773131207527444  best_feature\t None\n",
      "left_mistakes\t 707  right_mistakes\t 354  error\t 0.2773131207527444  best_feature\t grade.E\n",
      "left_mistakes\t 978  right_mistakes\t 83  error\t 0.2773131207527444  best_feature\t grade.E\n",
      "left_mistakes\t 0  right_mistakes\t 1061  error\t 0.2773131207527444  best_feature\t grade.E\n",
      "left_mistakes\t 478  right_mistakes\t 583  error\t 0.2773131207527444  best_feature\t grade.E\n",
      "left_mistakes\t 1060  right_mistakes\t 1  error\t 0.2773131207527444  best_feature\t grade.E\n",
      "left_mistakes\t 972  right_mistakes\t 89  error\t 0.2773131207527444  best_feature\t grade.E\n",
      "left_mistakes\t 673  right_mistakes\t 388  error\t 0.2773131207527444  best_feature\t grade.E\n",
      "left_mistakes\t 993  right_mistakes\t 68  error\t 0.2773131207527444  best_feature\t grade.E\n",
      "left_mistakes\t 694  right_mistakes\t 367  error\t 0.2773131207527444  best_feature\t grade.E\n",
      "left_mistakes\t 962  right_mistakes\t 99  error\t 0.2773131207527444  best_feature\t grade.E\n",
      "left_mistakes\t 978  right_mistakes\t 83  error\t 0.2773131207527444  best_feature\t grade.E\n",
      "left_mistakes\t 994  right_mistakes\t 67  error\t 0.2773131207527444  best_feature\t grade.E\n",
      "left_mistakes\t 973  right_mistakes\t 88  error\t 0.2773131207527444  best_feature\t grade.E\n",
      "left_mistakes\t 1008  right_mistakes\t 53  error\t 0.2773131207527444  best_feature\t grade.E\n",
      "left_mistakes\t 993  right_mistakes\t 68  error\t 0.2773131207527444  best_feature\t grade.E\n",
      "left_mistakes\t 1020  right_mistakes\t 41  error\t 0.2773131207527444  best_feature\t grade.E\n",
      "left_mistakes\t 1025  right_mistakes\t 36  error\t 0.2773131207527444  best_feature\t grade.E\n",
      "left_mistakes\t 991  right_mistakes\t 70  error\t 0.2773131207527444  best_feature\t grade.E\n",
      "left_mistakes\t 1040  right_mistakes\t 21  error\t 0.2773131207527444  best_feature\t grade.E\n",
      "Split on feature grade.E. (1693, 2133)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (1693 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (2133 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (2058 data points).\n",
      "left_mistakes\t 723  right_mistakes\t 0  error\t 0.35131195335276966  best_feature\t None\n",
      "left_mistakes\t 723  right_mistakes\t 0  error\t 0.35131195335276966  best_feature\t grade.E\n",
      "left_mistakes\t 723  right_mistakes\t 0  error\t 0.35131195335276966  best_feature\t grade.E\n",
      "left_mistakes\t 0  right_mistakes\t 723  error\t 0.35131195335276966  best_feature\t grade.E\n",
      "left_mistakes\t 285  right_mistakes\t 438  error\t 0.35131195335276966  best_feature\t grade.E\n",
      "left_mistakes\t 723  right_mistakes\t 0  error\t 0.35131195335276966  best_feature\t grade.E\n",
      "left_mistakes\t 675  right_mistakes\t 48  error\t 0.35131195335276966  best_feature\t grade.E\n",
      "left_mistakes\t 486  right_mistakes\t 237  error\t 0.35131195335276966  best_feature\t grade.E\n",
      "left_mistakes\t 689  right_mistakes\t 34  error\t 0.35131195335276966  best_feature\t grade.E\n",
      "left_mistakes\t 462  right_mistakes\t 261  error\t 0.35131195335276966  best_feature\t grade.E\n",
      "left_mistakes\t 658  right_mistakes\t 65  error\t 0.35131195335276966  best_feature\t grade.E\n",
      "left_mistakes\t 670  right_mistakes\t 53  error\t 0.35131195335276966  best_feature\t grade.E\n",
      "left_mistakes\t 678  right_mistakes\t 45  error\t 0.35131195335276966  best_feature\t grade.E\n",
      "left_mistakes\t 666  right_mistakes\t 57  error\t 0.35131195335276966  best_feature\t grade.E\n",
      "left_mistakes\t 686  right_mistakes\t 37  error\t 0.35131195335276966  best_feature\t grade.E\n",
      "left_mistakes\t 686  right_mistakes\t 37  error\t 0.35131195335276966  best_feature\t grade.E\n",
      "left_mistakes\t 684  right_mistakes\t 39  error\t 0.35131195335276966  best_feature\t grade.E\n",
      "left_mistakes\t 686  right_mistakes\t 37  error\t 0.35131195335276966  best_feature\t grade.E\n",
      "left_mistakes\t 677  right_mistakes\t 46  error\t 0.35131195335276966  best_feature\t grade.E\n",
      "left_mistakes\t 711  right_mistakes\t 12  error\t 0.35131195335276966  best_feature\t grade.E\n",
      "Split on feature grade.E. (2058, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (2190 data points).\n",
      "left_mistakes\t 914  right_mistakes\t 0  error\t 0.41735159817351597  best_feature\t None\n",
      "left_mistakes\t 914  right_mistakes\t 0  error\t 0.41735159817351597  best_feature\t grade.D\n",
      "left_mistakes\t 914  right_mistakes\t 0  error\t 0.41735159817351597  best_feature\t grade.D\n",
      "left_mistakes\t 914  right_mistakes\t 0  error\t 0.41735159817351597  best_feature\t grade.D\n",
      "left_mistakes\t 0  right_mistakes\t 914  error\t 0.41735159817351597  best_feature\t grade.D\n",
      "left_mistakes\t 306  right_mistakes\t 608  error\t 0.41735159817351597  best_feature\t grade.D\n",
      "left_mistakes\t 914  right_mistakes\t 0  error\t 0.41735159817351597  best_feature\t grade.D\n",
      "left_mistakes\t 850  right_mistakes\t 64  error\t 0.41735159817351597  best_feature\t grade.D\n",
      "left_mistakes\t 672  right_mistakes\t 242  error\t 0.41735159817351597  best_feature\t grade.D\n",
      "left_mistakes\t 868  right_mistakes\t 46  error\t 0.41735159817351597  best_feature\t grade.D\n",
      "left_mistakes\t 572  right_mistakes\t 342  error\t 0.41735159817351597  best_feature\t grade.D\n",
      "left_mistakes\t 847  right_mistakes\t 67  error\t 0.41735159817351597  best_feature\t grade.D\n",
      "left_mistakes\t 847  right_mistakes\t 67  error\t 0.41735159817351597  best_feature\t grade.D\n",
      "left_mistakes\t 853  right_mistakes\t 61  error\t 0.41735159817351597  best_feature\t grade.D\n",
      "left_mistakes\t 847  right_mistakes\t 67  error\t 0.41735159817351597  best_feature\t grade.D\n",
      "left_mistakes\t 861  right_mistakes\t 53  error\t 0.41735159817351597  best_feature\t grade.D\n",
      "left_mistakes\t 857  right_mistakes\t 57  error\t 0.41735159817351597  best_feature\t grade.D\n",
      "left_mistakes\t 873  right_mistakes\t 41  error\t 0.41735159817351597  best_feature\t grade.D\n",
      "left_mistakes\t 884  right_mistakes\t 30  error\t 0.41735159817351597  best_feature\t grade.D\n",
      "left_mistakes\t 837  right_mistakes\t 77  error\t 0.41735159817351597  best_feature\t grade.D\n",
      "left_mistakes\t 908  right_mistakes\t 6  error\t 0.41735159817351597  best_feature\t grade.D\n",
      "Split on feature grade.D. (2190, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (1048 data points).\n",
      "left_mistakes\t 461  right_mistakes\t 0  error\t 0.4398854961832061  best_feature\t None\n",
      "left_mistakes\t 461  right_mistakes\t 0  error\t 0.4398854961832061  best_feature\t grade.C\n",
      "left_mistakes\t 461  right_mistakes\t 0  error\t 0.4398854961832061  best_feature\t grade.C\n",
      "left_mistakes\t 461  right_mistakes\t 0  error\t 0.4398854961832061  best_feature\t grade.C\n",
      "left_mistakes\t 461  right_mistakes\t 0  error\t 0.4398854961832061  best_feature\t grade.C\n",
      "left_mistakes\t 0  right_mistakes\t 461  error\t 0.4398854961832061  best_feature\t grade.C\n",
      "left_mistakes\t 165  right_mistakes\t 296  error\t 0.4398854961832061  best_feature\t grade.C\n",
      "left_mistakes\t 461  right_mistakes\t 0  error\t 0.4398854961832061  best_feature\t grade.C\n",
      "left_mistakes\t 430  right_mistakes\t 31  error\t 0.4398854961832061  best_feature\t grade.C\n",
      "left_mistakes\t 327  right_mistakes\t 134  error\t 0.4398854961832061  best_feature\t grade.C\n",
      "left_mistakes\t 435  right_mistakes\t 26  error\t 0.4398854961832061  best_feature\t grade.C\n",
      "left_mistakes\t 311  right_mistakes\t 150  error\t 0.4398854961832061  best_feature\t grade.C\n",
      "left_mistakes\t 419  right_mistakes\t 42  error\t 0.4398854961832061  best_feature\t grade.C\n",
      "left_mistakes\t 431  right_mistakes\t 30  error\t 0.4398854961832061  best_feature\t grade.C\n",
      "left_mistakes\t 430  right_mistakes\t 31  error\t 0.4398854961832061  best_feature\t grade.C\n",
      "left_mistakes\t 420  right_mistakes\t 38  error\t 0.43702290076335876  best_feature\t grade.C\n",
      "left_mistakes\t 436  right_mistakes\t 25  error\t 0.4398854961832061  best_feature\t emp_length.5 years\n",
      "left_mistakes\t 436  right_mistakes\t 25  error\t 0.4398854961832061  best_feature\t emp_length.5 years\n",
      "left_mistakes\t 441  right_mistakes\t 20  error\t 0.4398854961832061  best_feature\t emp_length.5 years\n",
      "left_mistakes\t 440  right_mistakes\t 21  error\t 0.4398854961832061  best_feature\t emp_length.5 years\n",
      "left_mistakes\t 426  right_mistakes\t 35  error\t 0.4398854961832061  best_feature\t emp_length.5 years\n",
      "left_mistakes\t 446  right_mistakes\t 15  error\t 0.4398854961832061  best_feature\t emp_length.5 years\n",
      "Split on feature emp_length.5 years. (969, 79)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (969 data points).\n",
      "left_mistakes\t 420  right_mistakes\t 0  error\t 0.43343653250773995  best_feature\t None\n",
      "left_mistakes\t 420  right_mistakes\t 0  error\t 0.43343653250773995  best_feature\t grade.C\n",
      "left_mistakes\t 420  right_mistakes\t 0  error\t 0.43343653250773995  best_feature\t grade.C\n",
      "left_mistakes\t 420  right_mistakes\t 0  error\t 0.43343653250773995  best_feature\t grade.C\n",
      "left_mistakes\t 420  right_mistakes\t 0  error\t 0.43343653250773995  best_feature\t grade.C\n",
      "left_mistakes\t 0  right_mistakes\t 420  error\t 0.43343653250773995  best_feature\t grade.C\n",
      "left_mistakes\t 146  right_mistakes\t 274  error\t 0.43343653250773995  best_feature\t grade.C\n",
      "left_mistakes\t 420  right_mistakes\t 0  error\t 0.43343653250773995  best_feature\t grade.C\n",
      "left_mistakes\t 394  right_mistakes\t 26  error\t 0.43343653250773995  best_feature\t grade.C\n",
      "left_mistakes\t 300  right_mistakes\t 120  error\t 0.43343653250773995  best_feature\t grade.C\n",
      "left_mistakes\t 394  right_mistakes\t 26  error\t 0.43343653250773995  best_feature\t grade.C\n",
      "left_mistakes\t 270  right_mistakes\t 150  error\t 0.43343653250773995  best_feature\t grade.C\n",
      "left_mistakes\t 378  right_mistakes\t 42  error\t 0.43343653250773995  best_feature\t grade.C\n",
      "left_mistakes\t 390  right_mistakes\t 30  error\t 0.43343653250773995  best_feature\t grade.C\n",
      "left_mistakes\t 389  right_mistakes\t 31  error\t 0.43343653250773995  best_feature\t grade.C\n",
      "left_mistakes\t 395  right_mistakes\t 25  error\t 0.43343653250773995  best_feature\t grade.C\n",
      "left_mistakes\t 395  right_mistakes\t 25  error\t 0.43343653250773995  best_feature\t grade.C\n",
      "left_mistakes\t 400  right_mistakes\t 20  error\t 0.43343653250773995  best_feature\t grade.C\n",
      "left_mistakes\t 399  right_mistakes\t 21  error\t 0.43343653250773995  best_feature\t grade.C\n",
      "left_mistakes\t 385  right_mistakes\t 35  error\t 0.43343653250773995  best_feature\t grade.C\n",
      "left_mistakes\t 405  right_mistakes\t 15  error\t 0.43343653250773995  best_feature\t grade.C\n",
      "Split on feature grade.C. (969, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (79 data points).\n",
      "left_mistakes\t 38  right_mistakes\t 0  error\t 0.4810126582278481  best_feature\t None\n",
      "left_mistakes\t 38  right_mistakes\t 0  error\t 0.4810126582278481  best_feature\t grade.C\n",
      "left_mistakes\t 38  right_mistakes\t 0  error\t 0.4810126582278481  best_feature\t grade.C\n",
      "left_mistakes\t 38  right_mistakes\t 0  error\t 0.4810126582278481  best_feature\t grade.C\n",
      "left_mistakes\t 38  right_mistakes\t 0  error\t 0.4810126582278481  best_feature\t grade.C\n",
      "left_mistakes\t 0  right_mistakes\t 38  error\t 0.4810126582278481  best_feature\t grade.C\n",
      "left_mistakes\t 15  right_mistakes\t 22  error\t 0.46835443037974683  best_feature\t grade.C\n",
      "left_mistakes\t 38  right_mistakes\t 0  error\t 0.4810126582278481  best_feature\t home_ownership.MORTGAGE\n",
      "left_mistakes\t 34  right_mistakes\t 4  error\t 0.4810126582278481  best_feature\t home_ownership.MORTGAGE\n",
      "left_mistakes\t 27  right_mistakes\t 11  error\t 0.4810126582278481  best_feature\t home_ownership.MORTGAGE\n",
      "left_mistakes\t 38  right_mistakes\t 0  error\t 0.4810126582278481  best_feature\t home_ownership.MORTGAGE\n",
      "left_mistakes\t 38  right_mistakes\t 0  error\t 0.4810126582278481  best_feature\t home_ownership.MORTGAGE\n",
      "left_mistakes\t 38  right_mistakes\t 0  error\t 0.4810126582278481  best_feature\t home_ownership.MORTGAGE\n",
      "left_mistakes\t 38  right_mistakes\t 0  error\t 0.4810126582278481  best_feature\t home_ownership.MORTGAGE\n",
      "left_mistakes\t 38  right_mistakes\t 0  error\t 0.4810126582278481  best_feature\t home_ownership.MORTGAGE\n",
      "left_mistakes\t 38  right_mistakes\t 0  error\t 0.4810126582278481  best_feature\t home_ownership.MORTGAGE\n",
      "left_mistakes\t 38  right_mistakes\t 0  error\t 0.4810126582278481  best_feature\t home_ownership.MORTGAGE\n",
      "left_mistakes\t 38  right_mistakes\t 0  error\t 0.4810126582278481  best_feature\t home_ownership.MORTGAGE\n",
      "left_mistakes\t 38  right_mistakes\t 0  error\t 0.4810126582278481  best_feature\t home_ownership.MORTGAGE\n",
      "left_mistakes\t 38  right_mistakes\t 0  error\t 0.4810126582278481  best_feature\t home_ownership.MORTGAGE\n",
      "left_mistakes\t 38  right_mistakes\t 0  error\t 0.4810126582278481  best_feature\t home_ownership.MORTGAGE\n",
      "Split on feature home_ownership.MORTGAGE. (34, 45)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (34 data points).\n",
      "left_mistakes\t 15  right_mistakes\t 0  error\t 0.4411764705882353  best_feature\t None\n",
      "left_mistakes\t 15  right_mistakes\t 0  error\t 0.4411764705882353  best_feature\t grade.C\n",
      "left_mistakes\t 15  right_mistakes\t 0  error\t 0.4411764705882353  best_feature\t grade.C\n",
      "left_mistakes\t 15  right_mistakes\t 0  error\t 0.4411764705882353  best_feature\t grade.C\n",
      "left_mistakes\t 15  right_mistakes\t 0  error\t 0.4411764705882353  best_feature\t grade.C\n",
      "left_mistakes\t 0  right_mistakes\t 15  error\t 0.4411764705882353  best_feature\t grade.C\n",
      "left_mistakes\t 15  right_mistakes\t 0  error\t 0.4411764705882353  best_feature\t grade.C\n",
      "left_mistakes\t 11  right_mistakes\t 4  error\t 0.4411764705882353  best_feature\t grade.C\n",
      "left_mistakes\t 4  right_mistakes\t 11  error\t 0.4411764705882353  best_feature\t grade.C\n",
      "left_mistakes\t 15  right_mistakes\t 0  error\t 0.4411764705882353  best_feature\t grade.C\n",
      "left_mistakes\t 15  right_mistakes\t 0  error\t 0.4411764705882353  best_feature\t grade.C\n",
      "left_mistakes\t 15  right_mistakes\t 0  error\t 0.4411764705882353  best_feature\t grade.C\n",
      "left_mistakes\t 15  right_mistakes\t 0  error\t 0.4411764705882353  best_feature\t grade.C\n",
      "left_mistakes\t 15  right_mistakes\t 0  error\t 0.4411764705882353  best_feature\t grade.C\n",
      "left_mistakes\t 15  right_mistakes\t 0  error\t 0.4411764705882353  best_feature\t grade.C\n",
      "left_mistakes\t 15  right_mistakes\t 0  error\t 0.4411764705882353  best_feature\t grade.C\n",
      "left_mistakes\t 15  right_mistakes\t 0  error\t 0.4411764705882353  best_feature\t grade.C\n",
      "left_mistakes\t 15  right_mistakes\t 0  error\t 0.4411764705882353  best_feature\t grade.C\n",
      "left_mistakes\t 15  right_mistakes\t 0  error\t 0.4411764705882353  best_feature\t grade.C\n",
      "left_mistakes\t 15  right_mistakes\t 0  error\t 0.4411764705882353  best_feature\t grade.C\n",
      "Split on feature grade.C. (34, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (45 data points).\n",
      "left_mistakes\t 22  right_mistakes\t 0  error\t 0.4888888888888889  best_feature\t None\n",
      "left_mistakes\t 22  right_mistakes\t 0  error\t 0.4888888888888889  best_feature\t grade.C\n",
      "left_mistakes\t 22  right_mistakes\t 0  error\t 0.4888888888888889  best_feature\t grade.C\n",
      "left_mistakes\t 22  right_mistakes\t 0  error\t 0.4888888888888889  best_feature\t grade.C\n",
      "left_mistakes\t 22  right_mistakes\t 0  error\t 0.4888888888888889  best_feature\t grade.C\n",
      "left_mistakes\t 0  right_mistakes\t 22  error\t 0.4888888888888889  best_feature\t grade.C\n",
      "left_mistakes\t 22  right_mistakes\t 0  error\t 0.4888888888888889  best_feature\t grade.C\n",
      "left_mistakes\t 22  right_mistakes\t 0  error\t 0.4888888888888889  best_feature\t grade.C\n",
      "left_mistakes\t 22  right_mistakes\t 0  error\t 0.4888888888888889  best_feature\t grade.C\n",
      "left_mistakes\t 22  right_mistakes\t 0  error\t 0.4888888888888889  best_feature\t grade.C\n",
      "left_mistakes\t 22  right_mistakes\t 0  error\t 0.4888888888888889  best_feature\t grade.C\n",
      "left_mistakes\t 22  right_mistakes\t 0  error\t 0.4888888888888889  best_feature\t grade.C\n",
      "left_mistakes\t 22  right_mistakes\t 0  error\t 0.4888888888888889  best_feature\t grade.C\n",
      "left_mistakes\t 22  right_mistakes\t 0  error\t 0.4888888888888889  best_feature\t grade.C\n",
      "left_mistakes\t 22  right_mistakes\t 0  error\t 0.4888888888888889  best_feature\t grade.C\n",
      "left_mistakes\t 22  right_mistakes\t 0  error\t 0.4888888888888889  best_feature\t grade.C\n",
      "left_mistakes\t 22  right_mistakes\t 0  error\t 0.4888888888888889  best_feature\t grade.C\n",
      "left_mistakes\t 22  right_mistakes\t 0  error\t 0.4888888888888889  best_feature\t grade.C\n",
      "left_mistakes\t 22  right_mistakes\t 0  error\t 0.4888888888888889  best_feature\t grade.C\n",
      "left_mistakes\t 22  right_mistakes\t 0  error\t 0.4888888888888889  best_feature\t grade.C\n",
      "Split on feature grade.C. (45, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (101 data points).\n",
      "left_mistakes\t 39  right_mistakes\t 0  error\t 0.38613861386138615  best_feature\t None\n",
      "left_mistakes\t 39  right_mistakes\t 0  error\t 0.38613861386138615  best_feature\t grade.B\n",
      "left_mistakes\t 39  right_mistakes\t 0  error\t 0.38613861386138615  best_feature\t grade.B\n",
      "left_mistakes\t 39  right_mistakes\t 0  error\t 0.38613861386138615  best_feature\t grade.B\n",
      "left_mistakes\t 39  right_mistakes\t 0  error\t 0.38613861386138615  best_feature\t grade.B\n",
      "left_mistakes\t 39  right_mistakes\t 0  error\t 0.38613861386138615  best_feature\t grade.B\n",
      "left_mistakes\t 0  right_mistakes\t 39  error\t 0.38613861386138615  best_feature\t grade.B\n",
      "left_mistakes\t 16  right_mistakes\t 23  error\t 0.38613861386138615  best_feature\t grade.B\n",
      "left_mistakes\t 39  right_mistakes\t 0  error\t 0.38613861386138615  best_feature\t grade.B\n",
      "left_mistakes\t 36  right_mistakes\t 3  error\t 0.38613861386138615  best_feature\t grade.B\n",
      "left_mistakes\t 26  right_mistakes\t 13  error\t 0.38613861386138615  best_feature\t grade.B\n",
      "left_mistakes\t 37  right_mistakes\t 2  error\t 0.38613861386138615  best_feature\t grade.B\n",
      "left_mistakes\t 27  right_mistakes\t 12  error\t 0.38613861386138615  best_feature\t grade.B\n",
      "left_mistakes\t 37  right_mistakes\t 2  error\t 0.38613861386138615  best_feature\t grade.B\n",
      "left_mistakes\t 36  right_mistakes\t 3  error\t 0.38613861386138615  best_feature\t grade.B\n",
      "left_mistakes\t 37  right_mistakes\t 2  error\t 0.38613861386138615  best_feature\t grade.B\n",
      "left_mistakes\t 35  right_mistakes\t 4  error\t 0.38613861386138615  best_feature\t grade.B\n",
      "left_mistakes\t 36  right_mistakes\t 3  error\t 0.38613861386138615  best_feature\t grade.B\n",
      "left_mistakes\t 39  right_mistakes\t 0  error\t 0.38613861386138615  best_feature\t grade.B\n",
      "left_mistakes\t 38  right_mistakes\t 1  error\t 0.38613861386138615  best_feature\t grade.B\n",
      "left_mistakes\t 39  right_mistakes\t 0  error\t 0.38613861386138615  best_feature\t grade.B\n",
      "left_mistakes\t 33  right_mistakes\t 5  error\t 0.37623762376237624  best_feature\t grade.B\n",
      "left_mistakes\t 35  right_mistakes\t 1  error\t 0.3564356435643564  best_feature\t emp_length.< 1 year\n",
      "Split on feature emp_length.n/a. (96, 5)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (96 data points).\n",
      "left_mistakes\t 35  right_mistakes\t 0  error\t 0.3645833333333333  best_feature\t None\n",
      "left_mistakes\t 35  right_mistakes\t 0  error\t 0.3645833333333333  best_feature\t grade.B\n",
      "left_mistakes\t 35  right_mistakes\t 0  error\t 0.3645833333333333  best_feature\t grade.B\n",
      "left_mistakes\t 35  right_mistakes\t 0  error\t 0.3645833333333333  best_feature\t grade.B\n",
      "left_mistakes\t 35  right_mistakes\t 0  error\t 0.3645833333333333  best_feature\t grade.B\n",
      "left_mistakes\t 35  right_mistakes\t 0  error\t 0.3645833333333333  best_feature\t grade.B\n",
      "left_mistakes\t 0  right_mistakes\t 35  error\t 0.3645833333333333  best_feature\t grade.B\n",
      "left_mistakes\t 14  right_mistakes\t 21  error\t 0.3645833333333333  best_feature\t grade.B\n",
      "left_mistakes\t 35  right_mistakes\t 0  error\t 0.3645833333333333  best_feature\t grade.B\n",
      "left_mistakes\t 33  right_mistakes\t 2  error\t 0.3645833333333333  best_feature\t grade.B\n",
      "left_mistakes\t 23  right_mistakes\t 12  error\t 0.3645833333333333  best_feature\t grade.B\n",
      "left_mistakes\t 33  right_mistakes\t 2  error\t 0.3645833333333333  best_feature\t grade.B\n",
      "left_mistakes\t 23  right_mistakes\t 12  error\t 0.3645833333333333  best_feature\t grade.B\n",
      "left_mistakes\t 33  right_mistakes\t 2  error\t 0.3645833333333333  best_feature\t grade.B\n",
      "left_mistakes\t 32  right_mistakes\t 3  error\t 0.3645833333333333  best_feature\t grade.B\n",
      "left_mistakes\t 33  right_mistakes\t 2  error\t 0.3645833333333333  best_feature\t grade.B\n",
      "left_mistakes\t 31  right_mistakes\t 4  error\t 0.3645833333333333  best_feature\t grade.B\n",
      "left_mistakes\t 32  right_mistakes\t 3  error\t 0.3645833333333333  best_feature\t grade.B\n",
      "left_mistakes\t 35  right_mistakes\t 0  error\t 0.3645833333333333  best_feature\t grade.B\n",
      "left_mistakes\t 34  right_mistakes\t 1  error\t 0.3645833333333333  best_feature\t grade.B\n",
      "left_mistakes\t 35  right_mistakes\t 0  error\t 0.3645833333333333  best_feature\t grade.B\n",
      "left_mistakes\t 29  right_mistakes\t 5  error\t 0.3541666666666667  best_feature\t grade.B\n",
      "Split on feature emp_length.< 1 year. (85, 11)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (85 data points).\n",
      "left_mistakes\t 29  right_mistakes\t 0  error\t 0.3411764705882353  best_feature\t None\n",
      "left_mistakes\t 29  right_mistakes\t 0  error\t 0.3411764705882353  best_feature\t grade.B\n",
      "left_mistakes\t 29  right_mistakes\t 0  error\t 0.3411764705882353  best_feature\t grade.B\n",
      "left_mistakes\t 29  right_mistakes\t 0  error\t 0.3411764705882353  best_feature\t grade.B\n",
      "left_mistakes\t 29  right_mistakes\t 0  error\t 0.3411764705882353  best_feature\t grade.B\n",
      "left_mistakes\t 29  right_mistakes\t 0  error\t 0.3411764705882353  best_feature\t grade.B\n",
      "left_mistakes\t 0  right_mistakes\t 29  error\t 0.3411764705882353  best_feature\t grade.B\n",
      "left_mistakes\t 10  right_mistakes\t 19  error\t 0.3411764705882353  best_feature\t grade.B\n",
      "left_mistakes\t 29  right_mistakes\t 0  error\t 0.3411764705882353  best_feature\t grade.B\n",
      "left_mistakes\t 28  right_mistakes\t 1  error\t 0.3411764705882353  best_feature\t grade.B\n",
      "left_mistakes\t 20  right_mistakes\t 9  error\t 0.3411764705882353  best_feature\t grade.B\n",
      "left_mistakes\t 27  right_mistakes\t 2  error\t 0.3411764705882353  best_feature\t grade.B\n",
      "left_mistakes\t 17  right_mistakes\t 12  error\t 0.3411764705882353  best_feature\t grade.B\n",
      "left_mistakes\t 27  right_mistakes\t 2  error\t 0.3411764705882353  best_feature\t grade.B\n",
      "left_mistakes\t 26  right_mistakes\t 3  error\t 0.3411764705882353  best_feature\t grade.B\n",
      "left_mistakes\t 27  right_mistakes\t 2  error\t 0.3411764705882353  best_feature\t grade.B\n",
      "left_mistakes\t 25  right_mistakes\t 4  error\t 0.3411764705882353  best_feature\t grade.B\n",
      "left_mistakes\t 26  right_mistakes\t 3  error\t 0.3411764705882353  best_feature\t grade.B\n",
      "left_mistakes\t 29  right_mistakes\t 0  error\t 0.3411764705882353  best_feature\t grade.B\n",
      "left_mistakes\t 28  right_mistakes\t 1  error\t 0.3411764705882353  best_feature\t grade.B\n",
      "left_mistakes\t 29  right_mistakes\t 0  error\t 0.3411764705882353  best_feature\t grade.B\n",
      "Split on feature grade.B. (85, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (11 data points).\n",
      "left_mistakes\t 5  right_mistakes\t 0  error\t 0.45454545454545453  best_feature\t None\n",
      "left_mistakes\t 5  right_mistakes\t 0  error\t 0.45454545454545453  best_feature\t grade.B\n",
      "left_mistakes\t 5  right_mistakes\t 0  error\t 0.45454545454545453  best_feature\t grade.B\n",
      "left_mistakes\t 5  right_mistakes\t 0  error\t 0.45454545454545453  best_feature\t grade.B\n",
      "left_mistakes\t 5  right_mistakes\t 0  error\t 0.45454545454545453  best_feature\t grade.B\n",
      "left_mistakes\t 5  right_mistakes\t 0  error\t 0.45454545454545453  best_feature\t grade.B\n",
      "left_mistakes\t 0  right_mistakes\t 5  error\t 0.45454545454545453  best_feature\t grade.B\n",
      "left_mistakes\t 4  right_mistakes\t 1  error\t 0.45454545454545453  best_feature\t grade.B\n",
      "left_mistakes\t 5  right_mistakes\t 0  error\t 0.45454545454545453  best_feature\t grade.B\n",
      "left_mistakes\t 4  right_mistakes\t 1  error\t 0.45454545454545453  best_feature\t grade.B\n",
      "left_mistakes\t 2  right_mistakes\t 3  error\t 0.45454545454545453  best_feature\t grade.B\n",
      "left_mistakes\t 5  right_mistakes\t 0  error\t 0.45454545454545453  best_feature\t grade.B\n",
      "left_mistakes\t 5  right_mistakes\t 0  error\t 0.45454545454545453  best_feature\t grade.B\n",
      "left_mistakes\t 5  right_mistakes\t 0  error\t 0.45454545454545453  best_feature\t grade.B\n",
      "left_mistakes\t 5  right_mistakes\t 0  error\t 0.45454545454545453  best_feature\t grade.B\n",
      "left_mistakes\t 5  right_mistakes\t 0  error\t 0.45454545454545453  best_feature\t grade.B\n",
      "left_mistakes\t 5  right_mistakes\t 0  error\t 0.45454545454545453  best_feature\t grade.B\n",
      "left_mistakes\t 5  right_mistakes\t 0  error\t 0.45454545454545453  best_feature\t grade.B\n",
      "left_mistakes\t 5  right_mistakes\t 0  error\t 0.45454545454545453  best_feature\t grade.B\n",
      "left_mistakes\t 5  right_mistakes\t 0  error\t 0.45454545454545453  best_feature\t grade.B\n",
      "left_mistakes\t 5  right_mistakes\t 0  error\t 0.45454545454545453  best_feature\t grade.B\n",
      "Split on feature grade.B. (11, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (5 data points).\n",
      "left_mistakes\t 1  right_mistakes\t 0  error\t 0.2  best_feature\t None\n",
      "left_mistakes\t 1  right_mistakes\t 0  error\t 0.2  best_feature\t grade.B\n",
      "left_mistakes\t 1  right_mistakes\t 0  error\t 0.2  best_feature\t grade.B\n",
      "left_mistakes\t 1  right_mistakes\t 0  error\t 0.2  best_feature\t grade.B\n",
      "left_mistakes\t 1  right_mistakes\t 0  error\t 0.2  best_feature\t grade.B\n",
      "left_mistakes\t 1  right_mistakes\t 0  error\t 0.2  best_feature\t grade.B\n",
      "left_mistakes\t 0  right_mistakes\t 1  error\t 0.2  best_feature\t grade.B\n",
      "left_mistakes\t 0  right_mistakes\t 1  error\t 0.2  best_feature\t grade.B\n",
      "left_mistakes\t 1  right_mistakes\t 0  error\t 0.2  best_feature\t grade.B\n",
      "left_mistakes\t 1  right_mistakes\t 0  error\t 0.2  best_feature\t grade.B\n",
      "left_mistakes\t 1  right_mistakes\t 0  error\t 0.2  best_feature\t grade.B\n",
      "left_mistakes\t 1  right_mistakes\t 0  error\t 0.2  best_feature\t grade.B\n",
      "left_mistakes\t 1  right_mistakes\t 0  error\t 0.2  best_feature\t grade.B\n",
      "left_mistakes\t 1  right_mistakes\t 0  error\t 0.2  best_feature\t grade.B\n",
      "left_mistakes\t 1  right_mistakes\t 0  error\t 0.2  best_feature\t grade.B\n",
      "left_mistakes\t 1  right_mistakes\t 0  error\t 0.2  best_feature\t grade.B\n",
      "left_mistakes\t 1  right_mistakes\t 0  error\t 0.2  best_feature\t grade.B\n",
      "left_mistakes\t 1  right_mistakes\t 0  error\t 0.2  best_feature\t grade.B\n",
      "left_mistakes\t 1  right_mistakes\t 0  error\t 0.2  best_feature\t grade.B\n",
      "left_mistakes\t 1  right_mistakes\t 0  error\t 0.2  best_feature\t grade.B\n",
      "left_mistakes\t 1  right_mistakes\t 0  error\t 0.2  best_feature\t grade.B\n",
      "left_mistakes\t 1  right_mistakes\t 0  error\t 0.2  best_feature\t grade.B\n",
      "Split on feature grade.B. (5, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (28001 data points).\n",
      "left_mistakes\t 11255  right_mistakes\t 1219  error\t 0.4454840898539338  best_feature\t None\n",
      "left_mistakes\t 8718  right_mistakes\t 3756  error\t 0.4454840898539338  best_feature\t grade.A\n",
      "left_mistakes\t 8836  right_mistakes\t 3584  error\t 0.4435555873004536  best_feature\t grade.A\n",
      "left_mistakes\t 9733  right_mistakes\t 1960  error\t 0.4175922288489697  best_feature\t grade.C\n",
      "left_mistakes\t 11675  right_mistakes\t 477  error\t 0.43398450055355164  best_feature\t grade.D\n",
      "left_mistakes\t 12224  right_mistakes\t 108  error\t 0.44041284239848577  best_feature\t grade.D\n",
      "left_mistakes\t 12403  right_mistakes\t 26  error\t 0.4438770043927003  best_feature\t grade.D\n",
      "left_mistakes\t 12474  right_mistakes\t 0  error\t 0.4454840898539338  best_feature\t grade.D\n",
      "left_mistakes\t 7623  right_mistakes\t 4851  error\t 0.4454840898539338  best_feature\t grade.D\n",
      "left_mistakes\t 12443  right_mistakes\t 27  error\t 0.4453412378129353  best_feature\t grade.D\n",
      "left_mistakes\t 11392  right_mistakes\t 1082  error\t 0.4454840898539338  best_feature\t grade.D\n",
      "left_mistakes\t 5964  right_mistakes\t 6510  error\t 0.4454840898539338  best_feature\t grade.D\n",
      "left_mistakes\t 11536  right_mistakes\t 938  error\t 0.4454840898539338  best_feature\t grade.D\n",
      "left_mistakes\t 9391  right_mistakes\t 3083  error\t 0.4454840898539338  best_feature\t grade.D\n",
      "left_mistakes\t 11256  right_mistakes\t 1218  error\t 0.4454840898539338  best_feature\t grade.D\n",
      "left_mistakes\t 11409  right_mistakes\t 1065  error\t 0.4454840898539338  best_feature\t grade.D\n",
      "left_mistakes\t 11624  right_mistakes\t 850  error\t 0.4454840898539338  best_feature\t grade.D\n",
      "left_mistakes\t 11497  right_mistakes\t 977  error\t 0.4454840898539338  best_feature\t grade.D\n",
      "left_mistakes\t 11668  right_mistakes\t 806  error\t 0.4454840898539338  best_feature\t grade.D\n",
      "left_mistakes\t 11785  right_mistakes\t 689  error\t 0.4454840898539338  best_feature\t grade.D\n",
      "left_mistakes\t 11943  right_mistakes\t 531  error\t 0.4454840898539338  best_feature\t grade.D\n",
      "left_mistakes\t 12072  right_mistakes\t 402  error\t 0.4454840898539338  best_feature\t grade.D\n",
      "left_mistakes\t 11273  right_mistakes\t 1201  error\t 0.4454840898539338  best_feature\t grade.D\n",
      "left_mistakes\t 11760  right_mistakes\t 503  error\t 0.43794864469126105  best_feature\t grade.D\n",
      "Split on feature grade.D. (23300, 4701)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (23300 data points).\n",
      "left_mistakes\t 8514  right_mistakes\t 1219  error\t 0.417725321888412  best_feature\t None\n",
      "left_mistakes\t 5977  right_mistakes\t 3756  error\t 0.417725321888412  best_feature\t grade.A\n",
      "left_mistakes\t 6095  right_mistakes\t 3584  error\t 0.4154077253218884  best_feature\t grade.A\n",
      "left_mistakes\t 8934  right_mistakes\t 477  error\t 0.4039055793991416  best_feature\t grade.C\n",
      "left_mistakes\t 9483  right_mistakes\t 108  error\t 0.41163090128755364  best_feature\t grade.E\n",
      "left_mistakes\t 9662  right_mistakes\t 26  error\t 0.415793991416309  best_feature\t grade.E\n",
      "left_mistakes\t 9733  right_mistakes\t 0  error\t 0.417725321888412  best_feature\t grade.E\n",
      "left_mistakes\t 5755  right_mistakes\t 3978  error\t 0.417725321888412  best_feature\t grade.E\n",
      "left_mistakes\t 9709  right_mistakes\t 24  error\t 0.417725321888412  best_feature\t grade.E\n",
      "left_mistakes\t 8907  right_mistakes\t 826  error\t 0.417725321888412  best_feature\t grade.E\n",
      "left_mistakes\t 4828  right_mistakes\t 4905  error\t 0.417725321888412  best_feature\t grade.E\n",
      "left_mistakes\t 9010  right_mistakes\t 723  error\t 0.417725321888412  best_feature\t grade.E\n",
      "left_mistakes\t 7315  right_mistakes\t 2418  error\t 0.417725321888412  best_feature\t grade.E\n",
      "left_mistakes\t 8789  right_mistakes\t 944  error\t 0.417725321888412  best_feature\t grade.E\n",
      "left_mistakes\t 8913  right_mistakes\t 820  error\t 0.417725321888412  best_feature\t grade.E\n",
      "left_mistakes\t 9073  right_mistakes\t 660  error\t 0.417725321888412  best_feature\t grade.E\n",
      "left_mistakes\t 8960  right_mistakes\t 773  error\t 0.417725321888412  best_feature\t grade.E\n",
      "left_mistakes\t 9113  right_mistakes\t 620  error\t 0.417725321888412  best_feature\t grade.E\n",
      "left_mistakes\t 9204  right_mistakes\t 529  error\t 0.417725321888412  best_feature\t grade.E\n",
      "left_mistakes\t 9321  right_mistakes\t 412  error\t 0.417725321888412  best_feature\t grade.E\n",
      "left_mistakes\t 9411  right_mistakes\t 322  error\t 0.417725321888412  best_feature\t grade.E\n",
      "left_mistakes\t 8793  right_mistakes\t 940  error\t 0.417725321888412  best_feature\t grade.E\n",
      "left_mistakes\t 9161  right_mistakes\t 438  error\t 0.4119742489270386  best_feature\t grade.E\n",
      "Split on feature grade.E. (22024, 1276)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (22024 data points).\n",
      "left_mistakes\t 7715  right_mistakes\t 1219  error\t 0.4056483835815474  best_feature\t None\n",
      "left_mistakes\t 5178  right_mistakes\t 3756  error\t 0.4056483835815474  best_feature\t grade.A\n",
      "left_mistakes\t 5296  right_mistakes\t 3584  error\t 0.4031965128950236  best_feature\t grade.A\n",
      "left_mistakes\t 8684  right_mistakes\t 108  error\t 0.3992008717762441  best_feature\t grade.C\n",
      "left_mistakes\t 8863  right_mistakes\t 26  error\t 0.40360515800944424  best_feature\t grade.F\n",
      "left_mistakes\t 8934  right_mistakes\t 0  error\t 0.4056483835815474  best_feature\t grade.F\n",
      "left_mistakes\t 5201  right_mistakes\t 3733  error\t 0.4056483835815474  best_feature\t grade.F\n",
      "left_mistakes\t 8914  right_mistakes\t 20  error\t 0.4056483835815474  best_feature\t grade.F\n",
      "left_mistakes\t 8181  right_mistakes\t 753  error\t 0.4056483835815474  best_feature\t grade.F\n",
      "left_mistakes\t 4506  right_mistakes\t 4428  error\t 0.4056483835815474  best_feature\t grade.F\n",
      "left_mistakes\t 8272  right_mistakes\t 662  error\t 0.4056483835815474  best_feature\t grade.F\n",
      "left_mistakes\t 6702  right_mistakes\t 2232  error\t 0.4056483835815474  best_feature\t grade.F\n",
      "left_mistakes\t 8084  right_mistakes\t 850  error\t 0.4056483835815474  best_feature\t grade.F\n",
      "left_mistakes\t 8182  right_mistakes\t 752  error\t 0.4056483835815474  best_feature\t grade.F\n",
      "left_mistakes\t 8340  right_mistakes\t 594  error\t 0.4056483835815474  best_feature\t grade.F\n",
      "left_mistakes\t 8215  right_mistakes\t 719  error\t 0.4056483835815474  best_feature\t grade.F\n",
      "left_mistakes\t 8352  right_mistakes\t 582  error\t 0.4056483835815474  best_feature\t grade.F\n",
      "left_mistakes\t 8446  right_mistakes\t 488  error\t 0.4056483835815474  best_feature\t grade.F\n",
      "left_mistakes\t 8554  right_mistakes\t 380  error\t 0.4056483835815474  best_feature\t grade.F\n",
      "left_mistakes\t 8639  right_mistakes\t 295  error\t 0.4056483835815474  best_feature\t grade.F\n",
      "left_mistakes\t 8082  right_mistakes\t 852  error\t 0.4056483835815474  best_feature\t grade.F\n",
      "left_mistakes\t 8406  right_mistakes\t 421  error\t 0.4007900472212132  best_feature\t grade.F\n",
      "Split on feature grade.F. (21666, 358)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (21666 data points).\n",
      "left_mistakes\t 7465  right_mistakes\t 1219  error\t 0.4008123326871596  best_feature\t None\n",
      "left_mistakes\t 4928  right_mistakes\t 3756  error\t 0.4008123326871596  best_feature\t grade.A\n",
      "left_mistakes\t 5046  right_mistakes\t 3584  error\t 0.39831994830610173  best_feature\t grade.A\n",
      "left_mistakes\t 8613  right_mistakes\t 26  error\t 0.3987353457029447  best_feature\t grade.C\n",
      "left_mistakes\t 8684  right_mistakes\t 0  error\t 0.4008123326871596  best_feature\t grade.C\n",
      "left_mistakes\t 5032  right_mistakes\t 3652  error\t 0.4008123326871596  best_feature\t grade.C\n",
      "left_mistakes\t 8666  right_mistakes\t 18  error\t 0.4008123326871596  best_feature\t grade.C\n",
      "left_mistakes\t 7957  right_mistakes\t 727  error\t 0.4008123326871596  best_feature\t grade.C\n",
      "left_mistakes\t 4397  right_mistakes\t 4287  error\t 0.4008123326871596  best_feature\t grade.C\n",
      "left_mistakes\t 8048  right_mistakes\t 636  error\t 0.4008123326871596  best_feature\t grade.C\n",
      "left_mistakes\t 6498  right_mistakes\t 2186  error\t 0.4008123326871596  best_feature\t grade.C\n",
      "left_mistakes\t 7860  right_mistakes\t 824  error\t 0.4008123326871596  best_feature\t grade.C\n",
      "left_mistakes\t 7961  right_mistakes\t 723  error\t 0.4008123326871596  best_feature\t grade.C\n",
      "left_mistakes\t 8110  right_mistakes\t 574  error\t 0.4008123326871596  best_feature\t grade.C\n",
      "left_mistakes\t 7983  right_mistakes\t 701  error\t 0.4008123326871596  best_feature\t grade.C\n",
      "left_mistakes\t 8124  right_mistakes\t 560  error\t 0.4008123326871596  best_feature\t grade.C\n",
      "left_mistakes\t 8209  right_mistakes\t 475  error\t 0.4008123326871596  best_feature\t grade.C\n",
      "left_mistakes\t 8308  right_mistakes\t 376  error\t 0.4008123326871596  best_feature\t grade.C\n",
      "left_mistakes\t 8398  right_mistakes\t 286  error\t 0.4008123326871596  best_feature\t grade.C\n",
      "left_mistakes\t 7857  right_mistakes\t 827  error\t 0.4008123326871596  best_feature\t grade.C\n",
      "left_mistakes\t 8168  right_mistakes\t 416  error\t 0.39619680605557095  best_feature\t grade.C\n",
      "Split on feature emp_length.n/a. (20734, 932)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (20734 data points).\n",
      "left_mistakes\t 7036  right_mistakes\t 1132  error\t 0.3939423169673001  best_feature\t None\n",
      "left_mistakes\t 4631  right_mistakes\t 3537  error\t 0.3939423169673001  best_feature\t grade.A\n",
      "left_mistakes\t 4739  right_mistakes\t 3429  error\t 0.3939423169673001  best_feature\t grade.A\n",
      "left_mistakes\t 8098  right_mistakes\t 26  error\t 0.39182019870743706  best_feature\t grade.A\n",
      "left_mistakes\t 8168  right_mistakes\t 0  error\t 0.3939423169673001  best_feature\t grade.G\n",
      "left_mistakes\t 4736  right_mistakes\t 3432  error\t 0.3939423169673001  best_feature\t grade.G\n",
      "left_mistakes\t 8150  right_mistakes\t 18  error\t 0.3939423169673001  best_feature\t grade.G\n",
      "left_mistakes\t 7521  right_mistakes\t 647  error\t 0.3939423169673001  best_feature\t grade.G\n",
      "left_mistakes\t 4097  right_mistakes\t 4071  error\t 0.3939423169673001  best_feature\t grade.G\n",
      "left_mistakes\t 7532  right_mistakes\t 636  error\t 0.3939423169673001  best_feature\t grade.G\n",
      "left_mistakes\t 5982  right_mistakes\t 2186  error\t 0.3939423169673001  best_feature\t grade.G\n",
      "left_mistakes\t 7344  right_mistakes\t 824  error\t 0.3939423169673001  best_feature\t grade.G\n",
      "left_mistakes\t 7445  right_mistakes\t 723  error\t 0.3939423169673001  best_feature\t grade.G\n",
      "left_mistakes\t 7594  right_mistakes\t 574  error\t 0.3939423169673001  best_feature\t grade.G\n",
      "left_mistakes\t 7467  right_mistakes\t 701  error\t 0.3939423169673001  best_feature\t grade.G\n",
      "left_mistakes\t 7608  right_mistakes\t 560  error\t 0.3939423169673001  best_feature\t grade.G\n",
      "left_mistakes\t 7693  right_mistakes\t 475  error\t 0.3939423169673001  best_feature\t grade.G\n",
      "left_mistakes\t 7792  right_mistakes\t 376  error\t 0.3939423169673001  best_feature\t grade.G\n",
      "left_mistakes\t 7882  right_mistakes\t 286  error\t 0.3939423169673001  best_feature\t grade.G\n",
      "left_mistakes\t 7341  right_mistakes\t 827  error\t 0.3939423169673001  best_feature\t grade.G\n",
      "Split on feature grade.G. (20638, 96)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (20638 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (96 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (932 data points).\n",
      "left_mistakes\t 273  right_mistakes\t 87  error\t 0.38626609442060084  best_feature\t None\n",
      "left_mistakes\t 251  right_mistakes\t 165  error\t 0.44635193133047213  best_feature\t grade.A\n",
      "left_mistakes\t 307  right_mistakes\t 108  error\t 0.44527896995708155  best_feature\t grade.A\n",
      "left_mistakes\t 416  right_mistakes\t 0  error\t 0.44635193133047213  best_feature\t grade.A\n",
      "left_mistakes\t 416  right_mistakes\t 0  error\t 0.44635193133047213  best_feature\t grade.A\n",
      "left_mistakes\t 224  right_mistakes\t 192  error\t 0.44635193133047213  best_feature\t grade.A\n",
      "left_mistakes\t 415  right_mistakes\t 0  error\t 0.44527896995708155  best_feature\t grade.A\n",
      "left_mistakes\t 336  right_mistakes\t 80  error\t 0.44635193133047213  best_feature\t grade.A\n",
      "left_mistakes\t 273  right_mistakes\t 143  error\t 0.44635193133047213  best_feature\t grade.A\n",
      "left_mistakes\t 416  right_mistakes\t 0  error\t 0.44635193133047213  best_feature\t grade.A\n",
      "left_mistakes\t 416  right_mistakes\t 0  error\t 0.44635193133047213  best_feature\t grade.A\n",
      "left_mistakes\t 416  right_mistakes\t 0  error\t 0.44635193133047213  best_feature\t grade.A\n",
      "left_mistakes\t 416  right_mistakes\t 0  error\t 0.44635193133047213  best_feature\t grade.A\n",
      "left_mistakes\t 416  right_mistakes\t 0  error\t 0.44635193133047213  best_feature\t grade.A\n",
      "left_mistakes\t 416  right_mistakes\t 0  error\t 0.44635193133047213  best_feature\t grade.A\n",
      "left_mistakes\t 416  right_mistakes\t 0  error\t 0.44635193133047213  best_feature\t grade.A\n",
      "left_mistakes\t 416  right_mistakes\t 0  error\t 0.44635193133047213  best_feature\t grade.A\n",
      "left_mistakes\t 416  right_mistakes\t 0  error\t 0.44635193133047213  best_feature\t grade.A\n",
      "left_mistakes\t 416  right_mistakes\t 0  error\t 0.44635193133047213  best_feature\t grade.A\n",
      "left_mistakes\t 416  right_mistakes\t 0  error\t 0.44635193133047213  best_feature\t grade.A\n",
      "Split on feature grade.A. (702, 230)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (702 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (230 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (358 data points).\n",
      "left_mistakes\t 108  right_mistakes\t 0  error\t 0.3016759776536313  best_feature\t None\n",
      "left_mistakes\t 108  right_mistakes\t 0  error\t 0.3016759776536313  best_feature\t grade.A\n",
      "left_mistakes\t 108  right_mistakes\t 0  error\t 0.3016759776536313  best_feature\t grade.A\n",
      "left_mistakes\t 108  right_mistakes\t 0  error\t 0.3016759776536313  best_feature\t grade.A\n",
      "left_mistakes\t 108  right_mistakes\t 0  error\t 0.3016759776536313  best_feature\t grade.A\n",
      "left_mistakes\t 76  right_mistakes\t 32  error\t 0.3016759776536313  best_feature\t grade.A\n",
      "left_mistakes\t 108  right_mistakes\t 0  error\t 0.3016759776536313  best_feature\t grade.A\n",
      "left_mistakes\t 100  right_mistakes\t 8  error\t 0.3016759776536313  best_feature\t grade.A\n",
      "left_mistakes\t 40  right_mistakes\t 68  error\t 0.3016759776536313  best_feature\t grade.A\n",
      "left_mistakes\t 100  right_mistakes\t 8  error\t 0.3016759776536313  best_feature\t grade.A\n",
      "left_mistakes\t 89  right_mistakes\t 19  error\t 0.3016759776536313  best_feature\t grade.A\n",
      "left_mistakes\t 89  right_mistakes\t 19  error\t 0.3016759776536313  best_feature\t grade.A\n",
      "left_mistakes\t 101  right_mistakes\t 7  error\t 0.3016759776536313  best_feature\t grade.A\n",
      "left_mistakes\t 102  right_mistakes\t 6  error\t 0.3016759776536313  best_feature\t grade.A\n",
      "left_mistakes\t 99  right_mistakes\t 9  error\t 0.3016759776536313  best_feature\t grade.A\n",
      "left_mistakes\t 104  right_mistakes\t 4  error\t 0.3016759776536313  best_feature\t grade.A\n",
      "left_mistakes\t 103  right_mistakes\t 5  error\t 0.3016759776536313  best_feature\t grade.A\n",
      "left_mistakes\t 101  right_mistakes\t 4  error\t 0.29329608938547486  best_feature\t grade.A\n",
      "left_mistakes\t 108  right_mistakes\t 0  error\t 0.3016759776536313  best_feature\t emp_length.8 years\n",
      "left_mistakes\t 89  right_mistakes\t 19  error\t 0.3016759776536313  best_feature\t emp_length.8 years\n",
      "left_mistakes\t 103  right_mistakes\t 5  error\t 0.3016759776536313  best_feature\t emp_length.8 years\n",
      "Split on feature emp_length.8 years. (347, 11)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (347 data points).\n",
      "left_mistakes\t 101  right_mistakes\t 0  error\t 0.2910662824207493  best_feature\t None\n",
      "left_mistakes\t 101  right_mistakes\t 0  error\t 0.2910662824207493  best_feature\t grade.A\n",
      "left_mistakes\t 101  right_mistakes\t 0  error\t 0.2910662824207493  best_feature\t grade.A\n",
      "left_mistakes\t 101  right_mistakes\t 0  error\t 0.2910662824207493  best_feature\t grade.A\n",
      "left_mistakes\t 101  right_mistakes\t 0  error\t 0.2910662824207493  best_feature\t grade.A\n",
      "left_mistakes\t 72  right_mistakes\t 29  error\t 0.2910662824207493  best_feature\t grade.A\n",
      "left_mistakes\t 101  right_mistakes\t 0  error\t 0.2910662824207493  best_feature\t grade.A\n",
      "left_mistakes\t 93  right_mistakes\t 8  error\t 0.2910662824207493  best_feature\t grade.A\n",
      "left_mistakes\t 37  right_mistakes\t 64  error\t 0.2910662824207493  best_feature\t grade.A\n",
      "left_mistakes\t 93  right_mistakes\t 8  error\t 0.2910662824207493  best_feature\t grade.A\n",
      "left_mistakes\t 82  right_mistakes\t 19  error\t 0.2910662824207493  best_feature\t grade.A\n",
      "left_mistakes\t 82  right_mistakes\t 19  error\t 0.2910662824207493  best_feature\t grade.A\n",
      "left_mistakes\t 94  right_mistakes\t 7  error\t 0.2910662824207493  best_feature\t grade.A\n",
      "left_mistakes\t 95  right_mistakes\t 6  error\t 0.2910662824207493  best_feature\t grade.A\n",
      "left_mistakes\t 92  right_mistakes\t 9  error\t 0.2910662824207493  best_feature\t grade.A\n",
      "left_mistakes\t 97  right_mistakes\t 4  error\t 0.2910662824207493  best_feature\t grade.A\n",
      "left_mistakes\t 96  right_mistakes\t 5  error\t 0.2910662824207493  best_feature\t grade.A\n",
      "left_mistakes\t 101  right_mistakes\t 0  error\t 0.2910662824207493  best_feature\t grade.A\n",
      "left_mistakes\t 82  right_mistakes\t 19  error\t 0.2910662824207493  best_feature\t grade.A\n",
      "left_mistakes\t 96  right_mistakes\t 5  error\t 0.2910662824207493  best_feature\t grade.A\n",
      "Split on feature grade.A. (347, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (11 data points).\n",
      "left_mistakes\t 4  right_mistakes\t 0  error\t 0.36363636363636365  best_feature\t None\n",
      "left_mistakes\t 4  right_mistakes\t 0  error\t 0.36363636363636365  best_feature\t grade.A\n",
      "left_mistakes\t 4  right_mistakes\t 0  error\t 0.36363636363636365  best_feature\t grade.A\n",
      "left_mistakes\t 4  right_mistakes\t 0  error\t 0.36363636363636365  best_feature\t grade.A\n",
      "left_mistakes\t 4  right_mistakes\t 0  error\t 0.36363636363636365  best_feature\t grade.A\n",
      "left_mistakes\t 4  right_mistakes\t 0  error\t 0.36363636363636365  best_feature\t grade.A\n",
      "left_mistakes\t 4  right_mistakes\t 0  error\t 0.36363636363636365  best_feature\t grade.A\n",
      "left_mistakes\t 2  right_mistakes\t 0  error\t 0.18181818181818182  best_feature\t grade.A\n",
      "left_mistakes\t 2  right_mistakes\t 2  error\t 0.36363636363636365  best_feature\t home_ownership.OWN\n",
      "left_mistakes\t 4  right_mistakes\t 0  error\t 0.36363636363636365  best_feature\t home_ownership.OWN\n",
      "left_mistakes\t 4  right_mistakes\t 0  error\t 0.36363636363636365  best_feature\t home_ownership.OWN\n",
      "left_mistakes\t 4  right_mistakes\t 0  error\t 0.36363636363636365  best_feature\t home_ownership.OWN\n",
      "left_mistakes\t 4  right_mistakes\t 0  error\t 0.36363636363636365  best_feature\t home_ownership.OWN\n",
      "left_mistakes\t 4  right_mistakes\t 0  error\t 0.36363636363636365  best_feature\t home_ownership.OWN\n",
      "left_mistakes\t 4  right_mistakes\t 0  error\t 0.36363636363636365  best_feature\t home_ownership.OWN\n",
      "left_mistakes\t 4  right_mistakes\t 0  error\t 0.36363636363636365  best_feature\t home_ownership.OWN\n",
      "left_mistakes\t 4  right_mistakes\t 0  error\t 0.36363636363636365  best_feature\t home_ownership.OWN\n",
      "left_mistakes\t 4  right_mistakes\t 0  error\t 0.36363636363636365  best_feature\t home_ownership.OWN\n",
      "left_mistakes\t 4  right_mistakes\t 0  error\t 0.36363636363636365  best_feature\t home_ownership.OWN\n",
      "left_mistakes\t 4  right_mistakes\t 0  error\t 0.36363636363636365  best_feature\t home_ownership.OWN\n",
      "Split on feature home_ownership.OWN. (9, 2)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (9 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (2 data points).\n",
      "Stopping condition 1 reached.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (1276 data points).\n",
      "left_mistakes\t 477  right_mistakes\t 0  error\t 0.3738244514106583  best_feature\t None\n",
      "left_mistakes\t 477  right_mistakes\t 0  error\t 0.3738244514106583  best_feature\t grade.A\n",
      "left_mistakes\t 477  right_mistakes\t 0  error\t 0.3738244514106583  best_feature\t grade.A\n",
      "left_mistakes\t 477  right_mistakes\t 0  error\t 0.3738244514106583  best_feature\t grade.A\n",
      "left_mistakes\t 477  right_mistakes\t 0  error\t 0.3738244514106583  best_feature\t grade.A\n",
      "left_mistakes\t 477  right_mistakes\t 0  error\t 0.3738244514106583  best_feature\t grade.A\n",
      "left_mistakes\t 301  right_mistakes\t 176  error\t 0.3738244514106583  best_feature\t grade.A\n",
      "left_mistakes\t 475  right_mistakes\t 2  error\t 0.3738244514106583  best_feature\t grade.A\n",
      "left_mistakes\t 438  right_mistakes\t 39  error\t 0.3738244514106583  best_feature\t grade.A\n",
      "left_mistakes\t 217  right_mistakes\t 260  error\t 0.3738244514106583  best_feature\t grade.A\n",
      "left_mistakes\t 435  right_mistakes\t 42  error\t 0.3738244514106583  best_feature\t grade.A\n",
      "left_mistakes\t 362  right_mistakes\t 115  error\t 0.3738244514106583  best_feature\t grade.A\n",
      "left_mistakes\t 419  right_mistakes\t 58  error\t 0.3738244514106583  best_feature\t grade.A\n",
      "left_mistakes\t 428  right_mistakes\t 49  error\t 0.3738244514106583  best_feature\t grade.A\n",
      "left_mistakes\t 443  right_mistakes\t 34  error\t 0.3738244514106583  best_feature\t grade.A\n",
      "left_mistakes\t 457  right_mistakes\t 20  error\t 0.3738244514106583  best_feature\t grade.A\n",
      "left_mistakes\t 449  right_mistakes\t 28  error\t 0.3738244514106583  best_feature\t grade.A\n",
      "left_mistakes\t 455  right_mistakes\t 22  error\t 0.3738244514106583  best_feature\t grade.A\n",
      "left_mistakes\t 461  right_mistakes\t 16  error\t 0.3738244514106583  best_feature\t grade.A\n",
      "left_mistakes\t 462  right_mistakes\t 15  error\t 0.3738244514106583  best_feature\t grade.A\n",
      "left_mistakes\t 416  right_mistakes\t 61  error\t 0.3738244514106583  best_feature\t grade.A\n",
      "left_mistakes\t 460  right_mistakes\t 17  error\t 0.3738244514106583  best_feature\t grade.A\n",
      "Split on feature grade.A. (1276, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (4701 data points).\n",
      "left_mistakes\t 1960  right_mistakes\t 0  error\t 0.4169325675388215  best_feature\t None\n",
      "left_mistakes\t 1960  right_mistakes\t 0  error\t 0.4169325675388215  best_feature\t grade.A\n",
      "left_mistakes\t 1960  right_mistakes\t 0  error\t 0.4169325675388215  best_feature\t grade.A\n",
      "left_mistakes\t 1960  right_mistakes\t 0  error\t 0.4169325675388215  best_feature\t grade.A\n",
      "left_mistakes\t 1960  right_mistakes\t 0  error\t 0.4169325675388215  best_feature\t grade.A\n",
      "left_mistakes\t 1960  right_mistakes\t 0  error\t 0.4169325675388215  best_feature\t grade.A\n",
      "left_mistakes\t 1960  right_mistakes\t 0  error\t 0.4169325675388215  best_feature\t grade.A\n",
      "left_mistakes\t 1179  right_mistakes\t 781  error\t 0.4169325675388215  best_feature\t grade.A\n",
      "left_mistakes\t 1957  right_mistakes\t 3  error\t 0.4169325675388215  best_feature\t grade.A\n",
      "left_mistakes\t 1812  right_mistakes\t 148  error\t 0.4169325675388215  best_feature\t grade.A\n",
      "left_mistakes\t 932  right_mistakes\t 1028  error\t 0.4169325675388215  best_feature\t grade.A\n",
      "left_mistakes\t 1816  right_mistakes\t 144  error\t 0.4169325675388215  best_feature\t grade.A\n",
      "left_mistakes\t 1456  right_mistakes\t 504  error\t 0.4169325675388215  best_feature\t grade.A\n",
      "left_mistakes\t 1755  right_mistakes\t 205  error\t 0.4169325675388215  best_feature\t grade.A\n",
      "left_mistakes\t 1778  right_mistakes\t 182  error\t 0.4169325675388215  best_feature\t grade.A\n",
      "left_mistakes\t 1823  right_mistakes\t 137  error\t 0.4169325675388215  best_feature\t grade.A\n",
      "left_mistakes\t 1797  right_mistakes\t 163  error\t 0.4169325675388215  best_feature\t grade.A\n",
      "left_mistakes\t 1854  right_mistakes\t 106  error\t 0.4169325675388215  best_feature\t grade.A\n",
      "left_mistakes\t 1843  right_mistakes\t 117  error\t 0.4169325675388215  best_feature\t grade.A\n",
      "left_mistakes\t 1876  right_mistakes\t 84  error\t 0.4169325675388215  best_feature\t grade.A\n",
      "left_mistakes\t 1888  right_mistakes\t 72  error\t 0.4169325675388215  best_feature\t grade.A\n",
      "left_mistakes\t 1779  right_mistakes\t 181  error\t 0.4169325675388215  best_feature\t grade.A\n",
      "left_mistakes\t 1895  right_mistakes\t 65  error\t 0.4169325675388215  best_feature\t grade.A\n",
      "Split on feature grade.A. (4701, 0)\n",
      "Creating leaf node.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make sure to cap the depth at 6 by using max_depth = 6\n",
    "my_decision_tree = decision_tree_create(train_data, features, 'safe_loans', max_depth = 6)\n",
    "count_nodes(my_decision_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making predictions with a decision tree\n",
    "\n",
    "As discussed in the lecture, we can make predictions from the decision tree with a simple recursive function. Below, we call this function `classify`, which takes in a learned `tree` and a test point `x` to classify.  We include an option `annotate` that describes the prediction path when set to `True`.\n",
    "\n",
    "Fill in the places where you find `## YOUR CODE HERE`. There is **one** place in this function for you to fill in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(tree, x, annotate = False):   \n",
    "    # if the node is a leaf node.\n",
    "    if tree['is_leaf']:\n",
    "        if annotate: \n",
    "            print(\"At leaf, predicting %s\" % tree['prediction'])\n",
    "        return tree['prediction'] \n",
    "    else:\n",
    "        # split on feature.\n",
    "        split_feature_value = x[tree['splitting_feature']]\n",
    "        if annotate: \n",
    "            print(\"Split on %s = %s\" % (tree['splitting_feature'], split_feature_value))\n",
    "            \n",
    "        if split_feature_value == 0:\n",
    "            return classify(tree['left'], x, annotate)\n",
    "        else:\n",
    "            ### YOUR CODE HERE\n",
    "            return classify(tree['right'], x, annotate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's consider the first example of the test set and see what `my_decision_tree` model predicts for this data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'safe_loans': -1,\n",
       " 'grade.A': 0,\n",
       " 'grade.B': 0,\n",
       " 'grade.C': 0,\n",
       " 'grade.D': 1,\n",
       " 'grade.E': 0,\n",
       " 'grade.F': 0,\n",
       " 'grade.G': 0,\n",
       " 'term. 36 months': 0,\n",
       " 'term. 60 months': 1,\n",
       " 'home_ownership.MORTGAGE': 0,\n",
       " 'home_ownership.OTHER': 0,\n",
       " 'home_ownership.OWN': 0,\n",
       " 'home_ownership.RENT': 1,\n",
       " 'emp_length.1 year': 0,\n",
       " 'emp_length.10+ years': 0,\n",
       " 'emp_length.2 years': 1,\n",
       " 'emp_length.3 years': 0,\n",
       " 'emp_length.4 years': 0,\n",
       " 'emp_length.5 years': 0,\n",
       " 'emp_length.6 years': 0,\n",
       " 'emp_length.7 years': 0,\n",
       " 'emp_length.8 years': 0,\n",
       " 'emp_length.9 years': 0,\n",
       " 'emp_length.< 1 year': 0,\n",
       " 'emp_length.n/a': 0}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: -1 \n"
     ]
    }
   ],
   "source": [
    "print('Predicted class: %s ' % classify(my_decision_tree, test_data[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add some annotations to our prediction to see what the prediction path was that lead to this predicted class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split on term. 36 months = 0\n",
      "Split on grade.A = 0\n",
      "Split on grade.B = 0\n",
      "Split on grade.C = 0\n",
      "Split on grade.D = 1\n",
      "At leaf, predicting -1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify(my_decision_tree, test_data[0], annotate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question:** What was the feature that **my_decision_tree** first split on while making the prediction for test_data[0]?\n",
    "\n",
    "**A:** term. 36 months"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question:** What was the first feature that lead to a right split of test_data[0]?\n",
    "\n",
    "**A:** grade.D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question:** What was the last feature split on before reaching a leaf node for test_data[0]?\n",
    "\n",
    "**A:** grade.D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating your decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will write a function to evaluate a decision tree by computing the classification error of the tree on the given dataset.\n",
    "\n",
    "Again, recall that the **classification error** is defined as follows:\n",
    "$$\n",
    "\\mbox{classification error} = \\frac{\\mbox{# mistakes}}{\\mbox{# total examples}}\n",
    "$$\n",
    "\n",
    "Now, write a function called `evaluate_classification_error` that takes in as input:\n",
    "1. `tree` (as described above)\n",
    "2. `data` (an SFrame)\n",
    "3. `target` (a string - the name of the target/label column)\n",
    "\n",
    "This function should calculate a prediction (class label) for each row in `data` using the decision `tree` and return the classification error computed using the above formula. Fill in the places where you find `## YOUR CODE HERE`. There is **one** place in this function for you to fill in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classification_error(tree, data, target):\n",
    "    # Apply the classify(tree, x) to each row in your data\n",
    "    predictions = data.apply(lambda x: classify(tree, x))\n",
    "    \n",
    "    # Once you've made the predictions, calculate the classification error and return it\n",
    "    ## YOUR CODE HERE\n",
    "    mistakes = 0\n",
    "    for i, p in enumerate(predictions):\n",
    "        if p != data[i][target]:\n",
    "            mistakes += 1\n",
    "    #predictions['actual'] = data[target]\n",
    "    #mistakes = 0 # predictions.filter(,)\n",
    "    return mistakes / len(data)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's use this function to evaluate the classification error on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3837785437311504"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_classification_error(my_decision_tree, test_data, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question:** Rounded to 2nd decimal point, what is the classification error of **my_decision_tree** on the **test_data**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Printing out a decision stump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As discussed in the lecture, we can print out a single decision stump (printing out the entire tree is left as an exercise to the curious reader). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stump(tree, name = 'root'):\n",
    "    split_name = tree['splitting_feature'] # split_name is something like 'term. 36 months'\n",
    "    if split_name is None:\n",
    "        print(\"(leaf, label: %s)\" % tree['prediction'])\n",
    "        return None\n",
    "    split_feature, split_value = split_name.split('.')\n",
    "    print('                       %s' % name)\n",
    "    print('         |---------------|----------------|')\n",
    "    print('         |                                |')\n",
    "    print('         |                                |')\n",
    "    print('         |                                |')\n",
    "    print('  [{0} == 0]               [{0} == 1]    '.format(split_name))\n",
    "    print('         |                                |')\n",
    "    print('         |                                |')\n",
    "    print('         |                                |')\n",
    "    print('    (%s)                         (%s)' \\\n",
    "        % (('leaf, label: ' + str(tree['left']['prediction']) if tree['left']['is_leaf'] else 'subtree'),\n",
    "           ('leaf, label: ' + str(tree['right']['prediction']) if tree['right']['is_leaf'] else 'subtree')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       root\n",
      "         |---------------|----------------|\n",
      "         |                                |\n",
      "         |                                |\n",
      "         |                                |\n",
      "  [term. 36 months == 0]               [term. 36 months == 1]    \n",
      "         |                                |\n",
      "         |                                |\n",
      "         |                                |\n",
      "    (subtree)                         (subtree)\n"
     ]
    }
   ],
   "source": [
    "print_stump(my_decision_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question:** What is the feature that is used for the split at the root node?\n",
    "\n",
    "### Exploring the intermediate left subtree\n",
    "\n",
    "The tree is a recursive dictionary, so we do have access to all the nodes! We can use\n",
    "* `my_decision_tree['left']` to go left\n",
    "* `my_decision_tree['right']` to go right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       term. 36 months\n",
      "         |---------------|----------------|\n",
      "         |                                |\n",
      "         |                                |\n",
      "         |                                |\n",
      "  [grade.A == 0]               [grade.A == 1]    \n",
      "         |                                |\n",
      "         |                                |\n",
      "         |                                |\n",
      "    (subtree)                         (subtree)\n"
     ]
    }
   ],
   "source": [
    "print_stump(my_decision_tree['left'], my_decision_tree['splitting_feature'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the left subtree of the left subtree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       grade.A\n",
      "         |---------------|----------------|\n",
      "         |                                |\n",
      "         |                                |\n",
      "         |                                |\n",
      "  [grade.B == 0]               [grade.B == 1]    \n",
      "         |                                |\n",
      "         |                                |\n",
      "         |                                |\n",
      "    (subtree)                         (subtree)\n"
     ]
    }
   ],
   "source": [
    "print_stump(my_decision_tree['left']['left'], my_decision_tree['left']['splitting_feature'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question:** What is the path of the **first 3 feature splits** considered along the **left-most** branch of **my_decision_tree**?\n",
    "\n",
    "**A:** term. 36 months=0->grade.A=0->grade.B=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question:** What is the path of the **first 3 feature splits** considered along the **right-most** branch of **my_decision_tree**?\n",
    "\n",
    "**A:** term. 36 months == 1 -> grade.D == 1 -> (leaf) -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       root\n",
      "         |---------------|----------------|\n",
      "         |                                |\n",
      "         |                                |\n",
      "         |                                |\n",
      "  [term. 36 months == 0]               [term. 36 months == 1]    \n",
      "         |                                |\n",
      "         |                                |\n",
      "         |                                |\n",
      "    (subtree)                         (subtree)\n",
      "                       term. 36 months\n",
      "         |---------------|----------------|\n",
      "         |                                |\n",
      "         |                                |\n",
      "         |                                |\n",
      "  [grade.D == 0]               [grade.D == 1]    \n",
      "         |                                |\n",
      "         |                                |\n",
      "         |                                |\n",
      "    (subtree)                         (leaf, label: -1)\n",
      "(leaf, label: -1)\n"
     ]
    }
   ],
   "source": [
    "print_stump(my_decision_tree)\n",
    "print_stump(my_decision_tree['right'], my_decision_tree['splitting_feature'])\n",
    "print_stump(my_decision_tree['right']['right'], my_decision_tree['right']['splitting_feature'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
